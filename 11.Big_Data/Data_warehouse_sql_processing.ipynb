{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e4522f",
   "metadata": {},
   "source": [
    "- hive can use spark or mapreduce as engine , but it is just a methodology having purpose of datawarehouse management & batch processing.\n",
    "- real comparision is hive vs spark-sql\n",
    "- Use Hive with map-reduce engine for slow batch jobs, Spark-sql for fast flexible processing.\n",
    "- hive on spark engine is called hive-on-spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b464a",
   "metadata": {},
   "source": [
    "- SQL processing:\n",
    "    - Open Source: Apache Hive, Spark SQL (on Spark engine), Presto/Trino\n",
    "    - AWS: Redshift, Athena\n",
    "    - Azure: Synapse Analytics\n",
    "    - Google Cloud: BigQuery\n",
    "    - Commercial: Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121d024",
   "metadata": {},
   "source": [
    "# Hive Complete Reference Notes\n",
    "\n",
    "**1. Managed vs External Table Types**\n",
    "\n",
    "• Managed Tables (Internal Tables)\n",
    "  - `CREATE TABLE employees (id INT, name STRING, salary DOUBLE);`\n",
    "  - Hive manages both metadata and data storage\n",
    "  - Data stored in Hive warehouse directory (`/user/hive/warehouse` by default)\n",
    "  - When table is dropped, both metadata and data are deleted permanently\n",
    "  - Hive has full control over table lifecycle\n",
    "    * Creates directories automatically\n",
    "    * Manages file organization\n",
    "    * Handles data cleanup on DROP TABLE\n",
    "  - Best for tables entirely managed by Hive applications\n",
    "  - Default table type when not specified\n",
    "\n",
    "• External Tables\n",
    "  - `CREATE EXTERNAL TABLE ext_employees (id INT, name STRING) LOCATION '/user/data/employees';`\n",
    "  - Hive manages only metadata, not the actual data files\n",
    "  - Data stored in user-specified location outside Hive warehouse\n",
    "  - When table is dropped, only metadata is removed, data remains intact\n",
    "  - Data can be shared across multiple applications and tools\n",
    "    * Other systems can read/write the same data\n",
    "    * Data persists beyond Hive table lifecycle\n",
    "    * Useful for data lakes and shared storage scenarios\n",
    "  - Required when data already exists in specific HDFS location\n",
    "  - Safer option when data should not be accidentally deleted\n",
    "\n",
    "• Key differences and selection criteria\n",
    "  - **Data ownership**: Managed tables owned by Hive, external tables owned by user\n",
    "  - **Drop behavior**: Managed tables delete data, external tables preserve data\n",
    "  - **Location control**: Managed tables use warehouse, external tables use custom paths\n",
    "  - **Use managed for**: Temporary tables, Hive-specific processing, ETL intermediates\n",
    "  - **Use external for**: Shared data, existing datasets, data lake scenarios\n",
    "\n",
    "**2. Hive Table Types and Operations**\n",
    "\n",
    "• Staging tables concept\n",
    "  - Temporary tables used for data preprocessing and validation\n",
    "  - `CREATE TABLE staging_sales (date STRING, amount STRING, product STRING);`\n",
    "  - Often use STRING data types initially for flexible data loading\n",
    "  - Used to clean, validate, and transform data before loading to production tables\n",
    "    * Handle data quality issues\n",
    "    * Perform data type conversions\n",
    "    * Apply business rules and validations\n",
    "  - Typically dropped after successful data processing\n",
    "\n",
    "• Dropping tables safely\n",
    "  - `DROP TABLE table_name;`: Removes table completely\n",
    "  - `DROP TABLE IF EXISTS table_name;`: Prevents errors if table doesn't exist\n",
    "  - `TRUNCATE TABLE table_name;`: Removes all data but keeps table structure\n",
    "    * Faster than DELETE for removing all records\n",
    "    * Resets table to empty state\n",
    "    * Cannot be used with external tables\n",
    "  - `ALTER TABLE table_name DROP PARTITION (year=2023);`: Remove specific partitions\n",
    "\n",
    "• Table creation variations\n",
    "  - `CREATE TABLE LIKE existing_table;`: Copy structure without data\n",
    "  - `CREATE TABLE AS SELECT (CTAS);`: Create table with data from query\n",
    "  - `CREATE TEMPORARY TABLE temp_data (...);`: Session-specific tables\n",
    "    * Automatically dropped when session ends\n",
    "    * Not visible to other users or sessions\n",
    "    * Useful for intermediate processing steps\n",
    "\n",
    "**3. Data Loading: Local vs HDFS Operations**\n",
    "\n",
    "• Loading from local filesystem\n",
    "  - `LOAD DATA LOCAL INPATH '/home/user/data.txt' INTO TABLE employees;`\n",
    "  - Copies data from local file system to HDFS\n",
    "  - Original file remains in local filesystem\n",
    "  - Data transferred over network to HDFS\n",
    "    * Slower for large files due to network transfer\n",
    "    * Useful for small datasets and development\n",
    "    * File must exist on machine running Hive client\n",
    "  - `OVERWRITE` option replaces existing data\n",
    "\n",
    "• Moving from HDFS\n",
    "  - `LOAD DATA INPATH '/user/data/employees.txt' INTO TABLE employees;`\n",
    "  - Moves data files from HDFS location to table location\n",
    "  - Original files are moved, not copied\n",
    "    * Much faster operation (metadata update only)\n",
    "    * No additional storage space required\n",
    "    * Source files no longer exist in original location\n",
    "  - Preferred method for large datasets already in HDFS\n",
    "  - Files must be compatible with table schema and format\n",
    "\n",
    "• Loading considerations and best practices\n",
    "  - **Performance**: HDFS move operations much faster than local copy\n",
    "  - **Data formats**: Ensure file format matches table definition\n",
    "  - **Partitioning**: Use partition specification for partitioned tables\n",
    "  - **File organization**: Multiple files loaded as separate data files\n",
    "  - **Permissions**: Ensure proper HDFS permissions for data access\n",
    "  - **Validation**: Test with small datasets before bulk loading\n",
    "\n",
    "**4. Schema on Read Features**\n",
    "\n",
    "• Core concept and benefits\n",
    "  - Schema applied when data is read, not when data is written\n",
    "  - Data stored in raw format without immediate schema validation\n",
    "  - Flexible data ingestion without upfront schema definition\n",
    "    * Accept data in various formats and structures\n",
    "    * Handle schema evolution gracefully\n",
    "    * Support for semi-structured and unstructured data\n",
    "  - Contrast with traditional databases (schema on write)\n",
    "\n",
    "• Implementation in Hive\n",
    "  - `CREATE TABLE flexible_data (col1 STRING, col2 STRING, col3 STRING);`\n",
    "  - Data type conversion happens during query execution\n",
    "  - SerDe (Serializer/Deserializer) handles format interpretation\n",
    "    * JSON SerDe for JSON data\n",
    "    * Regex SerDe for custom text formats\n",
    "    * Avro SerDe for Avro files\n",
    "  - NULL values returned for incompatible data types\n",
    "\n",
    "• Advantages and considerations\n",
    "  - **Fast data ingestion**: No validation overhead during loading\n",
    "  - **Schema flexibility**: Handle varying data structures\n",
    "  - **Storage efficiency**: Store raw data without transformation\n",
    "  - **Query-time overhead**: Type conversion during each query\n",
    "  - **Data quality**: Potential issues discovered only during queries\n",
    "  - **Best practices**: Validate critical data paths and common queries\n",
    "\n",
    "**5. Creating Tables from Existing Tables**\n",
    "\n",
    "• CREATE TABLE AS SELECT (CTAS)\n",
    "  - `CREATE TABLE high_earners AS SELECT * FROM employees WHERE salary > 100000;`\n",
    "  - Creates new table with data populated from query results\n",
    "  - Schema automatically inferred from SELECT statement\n",
    "  - Data copied during table creation process\n",
    "    * New table independent of source table\n",
    "    * Snapshot of data at creation time\n",
    "    * Changes to source table don't affect new table\n",
    "  - Cannot specify additional table properties or detailed schema\n",
    "\n",
    "• CREATE TABLE LIKE\n",
    "  - `CREATE TABLE employees_backup LIKE employees;`\n",
    "  - Copies table structure without copying data\n",
    "  - Preserves column names, data types, and table properties\n",
    "  - Useful for creating backup tables or similar structures\n",
    "    * Maintains partitioning scheme\n",
    "    * Copies storage format and SerDe properties\n",
    "    * Preserves bucketing configuration\n",
    "  - Data loaded separately using INSERT or LOAD statements\n",
    "\n",
    "• Advanced table creation patterns\n",
    "  - `CREATE TABLE monthly_sales PARTITIONED BY (year INT, month INT) AS SELECT ...;`\n",
    "  - Combine CTAS with partitioning for organized data storage\n",
    "  - Use for creating materialized views and summary tables\n",
    "  - Efficient way to restructure existing data with new organization\n",
    "\n",
    "**6. Hive Partitions**\n",
    "\n",
    "• Partition types and concepts\n",
    "  - **Static partitioning**: Partition values specified explicitly\n",
    "  - **Dynamic partitioning**: Partition values determined from data\n",
    "  - Partitions create separate subdirectories for different partition values\n",
    "  - Dramatically improves query performance by partition pruning\n",
    "    * Queries scan only relevant partitions\n",
    "    * Reduces I/O and processing time\n",
    "    * Essential for time-series and categorical data organization\n",
    "\n",
    "• Static partition insertion\n",
    "  - `INSERT INTO TABLE sales PARTITION (year=2023, month=12) SELECT product, amount FROM staging_sales;`\n",
    "  - Partition values explicitly specified in INSERT statement\n",
    "  - All inserted records go to the same partition\n",
    "  - Simple and predictable partition assignment\n",
    "    * Full control over data placement\n",
    "    * Suitable for batch processing known time periods\n",
    "    * Prevents accidental data placement in wrong partitions\n",
    "\n",
    "• Static partition loading\n",
    "  - `LOAD DATA INPATH '/user/data/sales_2023_12.txt' INTO TABLE sales PARTITION (year=2023, month=12);`\n",
    "  - Data files loaded directly to specific partition\n",
    "  - Faster than INSERT for bulk data loading\n",
    "  - File-based partition population\n",
    "    * Maintains original file structure\n",
    "    * No data transformation during loading\n",
    "    * Efficient for pre-organized data files\n",
    "\n",
    "• Dynamic partitioning configuration\n",
    "  - `SET hive.exec.dynamic.partition=true;`: Enable dynamic partitioning\n",
    "  - `SET hive.exec.dynamic.partition.mode=nonstrict;`: Allow all dynamic partitions\n",
    "  - `SET hive.exec.max.dynamic.partitions=1000;`: Maximum partitions per node\n",
    "  - `SET hive.exec.max.dynamic.partitions.pernode=100;`: Maximum partitions per mapper\n",
    "\n",
    "• Dynamic partition insertion\n",
    "  - `INSERT INTO TABLE sales PARTITION (year, month) SELECT product, amount, year, month FROM staging_sales;`\n",
    "  - Partition values determined from data columns\n",
    "  - Automatically creates partitions based on distinct values\n",
    "  - Partition columns must be last in SELECT statement\n",
    "    * Order matters for multi-level partitioning\n",
    "    * Creates hierarchical directory structure\n",
    "    * Handles multiple partitions in single operation\n",
    "\n",
    "• Default and advanced partition handling\n",
    "  - `__HIVE_DEFAULT_PARTITION__`: Default name for NULL partition values\n",
    "  - `ALTER TABLE sales ADD PARTITION (year=2024, month=1);`: Manual partition creation\n",
    "  - `ALTER TABLE sales DROP PARTITION (year=2022);`: Remove old partitions\n",
    "  - Partition pruning optimization automatically applied in queries\n",
    "  - Regular partition maintenance required for optimal performance\n",
    "\n",
    "**7. Creating Tables from Sequence File Data**\n",
    "\n",
    "• Sequence file table creation\n",
    "  - `CREATE TABLE seq_employees (id INT, name STRING, salary DOUBLE) STORED AS SEQUENCEFILE;`\n",
    "  - Optimized for MapReduce processing and compression\n",
    "  - Binary format with better performance than text files\n",
    "  - Splittable format enabling parallel processing\n",
    "    * Each split processed by separate mapper\n",
    "    * Maintains record boundaries across splits\n",
    "    * Efficient for large dataset processing\n",
    "\n",
    "• Loading sequence file data\n",
    "  - `LOAD DATA INPATH '/user/data/employees.seq' INTO TABLE seq_employees;`\n",
    "  - Files must be in proper SequenceFile format\n",
    "  - Compatible with MapReduce input/output formats\n",
    "  - Preserves compression and serialization benefits\n",
    "    * Faster query processing\n",
    "    * Reduced storage requirements\n",
    "    * Better network utilization\n",
    "\n",
    "• Sequence file benefits and use cases\n",
    "  - **Performance**: Faster read/write operations than text files\n",
    "  - **Compression**: Efficient compression support (block and record level)\n",
    "  - **Splittability**: Enables parallel processing across cluster\n",
    "  - **Integration**: Native MapReduce compatibility\n",
    "  - **Use cases**: Large batch processing, ETL intermediates, compressed storage\n",
    "  - **Considerations**: Not human-readable, requires compatible tools\n",
    "\n",
    "**8. Hive Buckets (Clustering)**\n",
    "\n",
    "• Bucketing concept and implementation\n",
    "  - `CREATE TABLE bucketed_sales (id INT, product STRING, amount DOUBLE) CLUSTERED BY (id) INTO 4 BUCKETS;`\n",
    "  - Distributes data into fixed number of files based on hash function\n",
    "  - Hash function applied to bucketing column determines file placement\n",
    "  - Each bucket stored as separate file within table/partition directory\n",
    "    * Predictable file organization\n",
    "    * Consistent data distribution\n",
    "    * Enables sampling and join optimizations\n",
    "\n",
    "• Bucketing configuration and loading\n",
    "  - `SET hive.enforce.bucketing=true;`: Enable automatic bucketing\n",
    "  - `INSERT INTO TABLE bucketed_sales SELECT * FROM raw_sales;`\n",
    "  - Number of reducers should match number of buckets\n",
    "  - Hash function ensures even data distribution across buckets\n",
    "    * Prevents data skew in processing\n",
    "    * Enables efficient sampling queries\n",
    "    * Optimizes join operations between bucketed tables\n",
    "\n",
    "• Bucketing benefits and optimization\n",
    "  - **Sampling**: `SELECT * FROM bucketed_sales TABLESAMPLE(BUCKET 1 OUT OF 4);`\n",
    "  - **Join optimization**: Bucket joins for co-located data\n",
    "  - **Map-side joins**: Efficient joins when both tables bucketed on join key\n",
    "  - **Consistent performance**: Predictable query execution times\n",
    "    * Eliminates data skew issues\n",
    "    * Enables parallel processing optimizations\n",
    "    * Improves resource utilization\n",
    "\n",
    "• Advanced bucketing features\n",
    "  - `CLUSTERED BY (id) SORTED BY (timestamp) INTO 4 BUCKETS;`: Combine bucketing with sorting\n",
    "  - Sorted buckets enable faster range queries and aggregations\n",
    "  - Multiple column bucketing for complex data distribution\n",
    "  - Integration with partitioning for hierarchical data organization\n",
    "\n",
    "**9. Schema Evolution**\n",
    "\n",
    "• Schema evolution capabilities\n",
    "  - Add new columns to existing tables without data migration\n",
    "  - `ALTER TABLE employees ADD COLUMNS (department STRING, hire_date DATE);`\n",
    "  - New columns appear as NULL for existing records\n",
    "  - Maintains backward compatibility with existing data\n",
    "    * Old queries continue to work unchanged\n",
    "    * New queries can access additional columns\n",
    "    * No downtime required for schema changes\n",
    "\n",
    "• Column modification operations\n",
    "  - `ALTER TABLE employees CHANGE COLUMN name full_name STRING;`: Rename columns\n",
    "  - `ALTER TABLE employees CHANGE COLUMN salary salary DECIMAL(10,2);`: Change data types\n",
    "  - Compatible type changes preserve existing data\n",
    "  - Incompatible changes may require data conversion\n",
    "    * String to numeric conversions\n",
    "    * Date format standardization\n",
    "    * Precision and scale adjustments\n",
    "\n",
    "• Schema evolution best practices\n",
    "  - **Additive changes**: Safest approach - only add new columns\n",
    "  - **Default values**: Consider default values for new columns\n",
    "  - **Data validation**: Test schema changes with sample queries\n",
    "  - **Rollback planning**: Maintain ability to revert schema changes\n",
    "  - **Documentation**: Track schema evolution for data governance\n",
    "  - **Version control**: Maintain schema history and change logs\n",
    "\n",
    "• Handling schema conflicts\n",
    "  - SerDe-specific schema evolution capabilities\n",
    "  - Avro SerDe provides excellent schema evolution support\n",
    "  - JSON SerDe handles flexible schema changes\n",
    "  - Regular expressions updated for new data formats\n",
    "  - Partition-level schema variations supported\n",
    "\n",
    "**10. Executing HiveQL as Scripts**\n",
    "\n",
    "• Script execution methods\n",
    "  - `hive -f script.hql`: Execute HiveQL script from file\n",
    "  - `hive -e \"SELECT * FROM employees LIMIT 10;\"`: Execute single query\n",
    "  - `hive --hiveconf key=value -f script.hql`: Pass configuration parameters\n",
    "  - Scripts contain multiple HiveQL statements separated by semicolons\n",
    "    * Comments supported using -- or /* */ syntax\n",
    "    * Variable substitution using ${variable} syntax\n",
    "    * Conditional logic through Hive configuration\n",
    "\n",
    "• Script organization and best practices\n",
    "  - Use meaningful file names and directory structure\n",
    "  - Include header comments with purpose and parameters\n",
    "  - Organize statements logically (DDL, DML, cleanup)\n",
    "  - Handle errors gracefully with conditional statements\n",
    "    * Check table existence before operations\n",
    "    * Validate data quality at key checkpoints\n",
    "    * Include rollback procedures for complex operations\n",
    "\n",
    "• Variable substitution and parameterization\n",
    "  - `${hiveconf:start_date}`: Reference configuration variables\n",
    "  - `hive --hiveconf start_date=2023-01-01 -f monthly_report.hql`\n",
    "  - Environment variables accessible through ${env:VARIABLE}\n",
    "  - Dynamic script behavior based on runtime parameters\n",
    "    * Flexible date ranges for reports\n",
    "    * Environment-specific configurations\n",
    "    * Reusable script templates\n",
    "\n",
    "• Advanced scripting features\n",
    "  - `SET hive.cli.print.header=true;`: Print column headers\n",
    "  - `SET hive.exec.mode.local.auto=true;`: Enable local mode for small queries\n",
    "  - Source other script files for modular design\n",
    "  - Integration with shell scripts for complex workflows\n",
    "  - Error handling and logging strategies\n",
    "\n",
    "**11. Joins and Working with Dates**\n",
    "\n",
    "• Join types and syntax\n",
    "  - `SELECT a.*, b.* FROM employees a JOIN departments b ON a.dept_id = b.id;`: Inner join\n",
    "  - `LEFT OUTER JOIN`: Include all records from left table\n",
    "  - `RIGHT OUTER JOIN`: Include all records from right table\n",
    "  - `FULL OUTER JOIN`: Include all records from both tables\n",
    "  - `CROSS JOIN`: Cartesian product of both tables (use carefully)\n",
    "\n",
    "• Join optimization techniques\n",
    "  - **Map-side joins**: For small tables that fit in memory\n",
    "    * `/*+ MAPJOIN(small_table) */`: Hint for map-side join\n",
    "    * Broadcasts small table to all mappers\n",
    "    * Eliminates shuffle phase for better performance\n",
    "  - **Bucket map joins**: For bucketed tables on same column\n",
    "  - **Sort-merge bucket joins**: For sorted and bucketed tables\n",
    "    * Most efficient join for large tables\n",
    "    * Requires proper bucketing and sorting strategy\n",
    "\n",
    "• Date handling functions\n",
    "  - `SELECT CURRENT_DATE(), CURRENT_TIMESTAMP();`: Current date and time\n",
    "  - `SELECT YEAR(date_col), MONTH(date_col), DAY(date_col) FROM table;`: Extract date parts\n",
    "  - `SELECT DATE_ADD(date_col, 30), DATE_SUB(date_col, 7) FROM table;`: Date arithmetic\n",
    "  - `SELECT TO_DATE(timestamp_col) FROM table;`: Convert timestamp to date\n",
    "  - `SELECT UNIX_TIMESTAMP(date_string, 'yyyy-MM-dd') FROM table;`: Parse date strings\n",
    "\n",
    "• Date formatting and conversion\n",
    "  - `SELECT FROM_UNIXTIME(unix_timestamp, 'yyyy-MM-dd HH:mm:ss');`: Format Unix timestamp\n",
    "  - `SELECT DATE_FORMAT(date_col, 'yyyy-MM') FROM table;`: Custom date formatting\n",
    "  - `SELECT DATEDIFF(end_date, start_date) FROM table;`: Calculate date differences\n",
    "  - `SELECT WEEKOFYEAR(date_col), DAYOFWEEK(date_col) FROM table;`: Week and day functions\n",
    "\n",
    "• Date-based filtering and partitioning\n",
    "  - `WHERE date_col BETWEEN '2023-01-01' AND '2023-12-31'`: Date range filtering\n",
    "  - Use date functions in WHERE clauses for dynamic filtering\n",
    "  - Partition tables by date columns for optimal performance\n",
    "  - Consider time zone implications for timestamp data\n",
    "\n",
    "**12. MSCK REPAIR Command**\n",
    "\n",
    "• Purpose and functionality\n",
    "  - `MSCK REPAIR TABLE table_name;`: Synchronize metastore with HDFS\n",
    "  - Discovers partitions that exist in HDFS but not in Hive metastore\n",
    "  - Automatically adds missing partition metadata to metastore\n",
    "  - Essential after external partition creation or data loading\n",
    "    * Files added directly to HDFS bypass metastore updates\n",
    "    * External tools may create partitions unknown to Hive\n",
    "    * Data recovery scenarios require metastore synchronization\n",
    "\n",
    "• Common use cases\n",
    "  - After bulk data loading using external tools (Sqoop, Spark, etc.)\n",
    "  - Following direct HDFS operations that create partition directories\n",
    "  - Data recovery after metastore corruption or restoration\n",
    "  - Synchronization in multi-tenant environments\n",
    "    * Multiple applications writing to same table\n",
    "    * External ETL processes creating partitions\n",
    "    * Data lake scenarios with diverse data sources\n",
    "\n",
    "• MSCK REPAIR operation details\n",
    "  - Scans table's HDFS directory structure recursively\n",
    "  - Identifies partition directories based on naming convention\n",
    "  - Creates metastore entries for discovered partitions\n",
    "  - Does not validate data quality or schema compliance\n",
    "    * Only creates metadata entries\n",
    "    * Assumes proper partition structure exists\n",
    "    * May create entries for corrupted or incomplete partitions\n",
    "\n",
    "• Alternative partition management commands\n",
    "  - `ALTER TABLE table_name ADD PARTITION (year=2023, month=12);`: Manual partition addition\n",
    "  - `SHOW PARTITIONS table_name;`: List current partitions in metastore\n",
    "  - `DESCRIBE FORMATTED table_name PARTITION (year=2023);`: Partition details\n",
    "  - `ALTER TABLE table_name DROP PARTITION (year=2022);`: Remove partition metadata\n",
    "\n",
    "• Best practices and considerations\n",
    "  - Run MSCK REPAIR after bulk external data operations\n",
    "  - Monitor partition count to avoid excessive small partitions\n",
    "  - Validate critical partitions after repair operations\n",
    "  - Consider automation for regular synchronization needs\n",
    "  - Use with caution on tables with many partitions (performance impact)\n",
    "\n",
    "**13. Performance Tuning in Hive**\n",
    "\n",
    "• Query optimization techniques\n",
    "  - **Predicate pushdown**: Move WHERE clauses closer to data source\n",
    "    * Reduces data scanning and transfer\n",
    "    * Applied automatically by Hive optimizer\n",
    "    * More effective with columnar formats (Parquet, ORC)\n",
    "  - **Projection pruning**: Select only required columns\n",
    "    * `SELECT id, name FROM employees;` instead of `SELECT * FROM employees;`\n",
    "    * Reduces I/O and memory usage\n",
    "    * Critical for tables with many columns\n",
    "\n",
    "• Join optimization strategies\n",
    "  - **Map-side joins**: `/*+ MAPJOIN(small_table) */` for small dimension tables\n",
    "  - **Bucket joins**: Pre-bucket tables on join keys for efficient joins\n",
    "  - **Sort-merge bucket joins**: Ultimate optimization for large table joins\n",
    "  - **Join order**: Place largest table last in join sequence\n",
    "    * Hive optimizer reorders joins automatically\n",
    "    * Manual hints available for specific optimization needs\n",
    "\n",
    "• File format optimization\n",
    "  - **ORC format**: `STORED AS ORC` for best compression and performance\n",
    "    * Columnar storage with predicate pushdown\n",
    "    * Built-in indexing and statistics\n",
    "    * ACID transaction support\n",
    "  - **Parquet format**: Good alternative for cross-platform compatibility\n",
    "  - **Compression**: Enable compression for storage and I/O optimization\n",
    "    * `SET hive.exec.compress.output=true;`\n",
    "    * Choose appropriate codec (Snappy, ZLIB, LZO)\n",
    "\n",
    "• Partitioning and bucketing optimization\n",
    "  - **Partition pruning**: Query only relevant partitions\n",
    "    * Use partition columns in WHERE clauses\n",
    "    * Avoid functions on partition columns in filters\n",
    "    * Monitor partition count to prevent small file problem\n",
    "  - **Bucketing**: Distribute data evenly across files\n",
    "    * Enable sampling and map-side joins\n",
    "    * Prevent data skew in processing\n",
    "    * Optimize for specific query patterns\n",
    "\n",
    "• Memory and resource tuning\n",
    "  - **Mapper memory**: `mapreduce.map.memory.mb=2048`\n",
    "  - **Reducer memory**: `mapreduce.reduce.memory.mb=4096`\n",
    "  - **JVM heap settings**: Configure based on data size and complexity\n",
    "  - **Parallel execution**: `SET hive.exec.parallel=true;` for independent operations\n",
    "    * Multiple stages executed simultaneously\n",
    "    * Reduces overall job execution time\n",
    "    * Monitor resource usage to avoid oversubscription\n",
    "\n",
    "• Advanced optimization settings\n",
    "  - **Vectorization**: `SET hive.vectorized.execution.enabled=true;`\n",
    "    * Processes multiple rows together for better CPU utilization\n",
    "    * Significant performance improvement for analytical queries\n",
    "    * Works best with ORC file format\n",
    "  - **Cost-based optimizer**: `SET hive.cbo.enable=true;`\n",
    "    * Uses table statistics for better execution plans\n",
    "    * Requires regular statistics updates with `ANALYZE TABLE`\n",
    "  - **Dynamic partition pruning**: Automatic optimization for star schema queries\n",
    "\n",
    "• Monitoring and troubleshooting\n",
    "  - **Query plans**: `EXPLAIN SELECT ...;` to understand execution strategy\n",
    "  - **Statistics**: `ANALYZE TABLE table_name COMPUTE STATISTICS;` for optimizer\n",
    "  - **Job tracking**: Monitor MapReduce jobs through Hadoop UI\n",
    "  - **Identify bottlenecks**: CPU, memory, I/O, or network constraints\n",
    "    * Profile queries with different data sizes\n",
    "    * Test various optimization techniques\n",
    "    * Monitor resource utilization patterns\n",
    "  - **Small file problem**: Consolidate small files using concatenation or compaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c91deb",
   "metadata": {},
   "source": [
    "# presto/trino:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436496bf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
