{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f144ffe",
   "metadata": {},
   "source": [
    "\n",
    "## **PromptTemplate**\n",
    "\n",
    "* A core LangChain abstraction for structuring prompts.\n",
    "* Lets you define a **template string** with placeholders (like `{product}`), then fill them dynamically at runtime.\n",
    "* Useful because LLMs respond better to structured, consistent prompts instead of messy string concatenation.\n",
    "* Example:\n",
    "\n",
    "  ```python\n",
    "  from langchain.prompts import PromptTemplate\n",
    "\n",
    "  prompt = PromptTemplate(\n",
    "      input_variables=[\"product\"],\n",
    "      template=\"Write a tagline for {product}.\"\n",
    "  )\n",
    "  print(prompt.format(product=\"smartwatch\"))\n",
    "  ```\n",
    "* In real systems, PromptTemplate is critical for **standardizing prompts across pipelines**—for chatbots, knowledge assistants, or content generation tools.\n",
    "\n",
    "---\n",
    "\n",
    "## **Runnable (LCEL) vs LangGraph**\n",
    "\n",
    "1. **Runnable / LCEL (LangChain Expression Language)**\n",
    "\n",
    "   * LCEL makes LangChain components composable, like building blocks in a pipeline.\n",
    "   * Each step is a **Runnable** (prompt → model → parser).\n",
    "   * Encourages functional chaining: data flows through transforms.\n",
    "   * Example: `prompt | llm | parser`\n",
    "   * Ideal when you want **linear flows**—like passing user query → LLM → JSON output.\n",
    "   * Industry use: building **ETL-like LLM workflows** (parse documents, enrich, then output summaries).\n",
    "\n",
    "2. **LangGraph**\n",
    "\n",
    "   * Built on top of LCEL but for **graphs instead of chains**.\n",
    "   * Lets you design **state machines / DAGs (directed acyclic graphs)** where control flow depends on conditions.\n",
    "   * Can implement loops, branching, memory, retries.\n",
    "   * Example: Customer support bot where path depends on sentiment: positive → FAQ answer; negative → escalate to human.\n",
    "   * Industry use: **multi-agent orchestration** or complex **decision trees with LLMs**.\n",
    "\n",
    "---\n",
    "\n",
    "Simple metaphor:\n",
    "\n",
    "* **LCEL** = a train track, straight line, predictable stops.\n",
    "* **LangGraph** = a metro map, multiple routes, branches, loops, and junctions.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247f57a",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "- Langserver\n",
    "- Langsmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabe764",
   "metadata": {},
   "source": [
    "## Memory: \n",
    "## sessions(message History):\n",
    "## hub & agent executor:\n",
    "## tools (all including yt tool, serach tool, math tools, embeeding tools, indexing tools ):\n",
    "## sql toolkit vs mcp : \n",
    "## stuff document chain text summarization vs map reduce summarization technique with single prompt and multiple prompt template vs refine chain summarization:\n",
    "## huggingfaceXlangchain features:\n",
    "##  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc98808",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
