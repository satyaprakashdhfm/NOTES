{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db3eb10",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Quick Reference Summary\n",
    "\n",
    "### Most Common Operations by Category\n",
    "\n",
    "**Data Import/Export:** `read_csv()`, `read_excel()`, `to_csv()`, `to_excel()`, `read_sql()`, `to_sql()`\n",
    "\n",
    "**Data Inspection:** `head()`, `tail()`, `info()`, `describe()`, `shape`, `dtypes`, `columns`, `index`\n",
    "\n",
    "**Selection:** `loc[]`, `iloc[]`, `[]`, `query()`, `at[]`, `iat[]`\n",
    "\n",
    "**Cleaning:** `dropna()`, `fillna()`, `drop_duplicates()`, `replace()`, `rename()`\n",
    "\n",
    "**Transformation:** `apply()`, `map()`, `applymap()`, `assign()`, `pipe()`\n",
    "\n",
    "**Aggregation:** `groupby()`, `agg()`, `pivot_table()`, `crosstab()`\n",
    "\n",
    "**Combining:** `merge()`, `join()`, `concat()`, `append()`\n",
    "\n",
    "**Reshaping:** `pivot()`, `melt()`, `stack()`, `unstack()`, `transpose()`\n",
    "\n",
    "**String Operations:** `.str.` methods (lower, upper, contains, replace, split, etc.)\n",
    "\n",
    "**DateTime:** `.dt.` methods (year, month, day, strftime, etc.), `to_datetime()`\n",
    "\n",
    "**Statistics:** `mean()`, `median()`, `sum()`, `std()`, `corr()`, `describe()`\n",
    "\n",
    "**Sorting:** `sort_values()`, `sort_index()`, `rank()`\n",
    "\n",
    "**Window Functions:** `rolling()`, `expanding()`, `ewm()`\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Learning Pandas Efficiently\n",
    "\n",
    "1. **Start with Level 1** - Master basic operations before moving to advanced features\n",
    "2. **Practice with real datasets** - Use Kaggle datasets or create your own\n",
    "3. **Use method chaining** - Makes code more readable and efficient\n",
    "4. **Learn one category at a time** - Don't try to memorize everything at once\n",
    "5. **Understand the difference between** Series and DataFrame operations\n",
    "6. **Always check the documentation** - `help(df.function)` or `df.function?` in Jupyter\n",
    "7. **Use vectorized operations** - Avoid loops whenever possible for performance\n",
    "8. **Experiment in Jupyter notebooks** - Great for learning and testing\n",
    "9. **Learn keyboard shortcuts** - `Tab` for autocomplete, `Shift+Tab` for documentation\n",
    "10. **Practice, practice, practice** - The more you use it, the more natural it becomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb996ab7",
   "metadata": {},
   "source": [
    "# Complete Pandas Reference Guide - Level 1 to 3\n",
    "\n",
    "## Table of Contents\n",
    "- [Level 1: Beginner Functions](#level-1-beginner-functions)\n",
    "- [Level 2: Intermediate Functions](#level-2-intermediate-functions)\n",
    "- [Level 3: Advanced Functions](#level-3-advanced-functions)\n",
    "\n",
    "---\n",
    "\n",
    "## Level 1: Beginner Functions\n",
    "\n",
    "### Importing Pandas\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "### Creating DataFrames and Series\n",
    "\n",
    "#### `pd.DataFrame()`\n",
    "Creates a DataFrame from various data structures.\n",
    "```python\n",
    "# From dictionary\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# From list of lists\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])\n",
    "\n",
    "# From numpy array\n",
    "df = pd.DataFrame(np.array([[1, 2], [3, 4]]), columns=['A', 'B'])\n",
    "```\n",
    "\n",
    "#### `pd.Series()`\n",
    "Creates a one-dimensional labeled array.\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "```\n",
    "\n",
    "### Reading and Writing Data\n",
    "\n",
    "#### `pd.read_csv()`\n",
    "Reads a CSV file into a DataFrame.\n",
    "```python\n",
    "df = pd.read_csv('file.csv')\n",
    "df = pd.read_csv('file.csv', sep=';', header=0, index_col=0)\n",
    "```\n",
    "\n",
    "#### `pd.read_excel()`\n",
    "Reads an Excel file into a DataFrame.\n",
    "```python\n",
    "df = pd.read_excel('file.xlsx', sheet_name='Sheet1')\n",
    "```\n",
    "\n",
    "#### `pd.read_json()`\n",
    "Reads a JSON file into a DataFrame.\n",
    "```python\n",
    "df = pd.read_json('file.json')\n",
    "```\n",
    "\n",
    "#### `df.to_csv()`\n",
    "Writes DataFrame to a CSV file.\n",
    "```python\n",
    "df.to_csv('output.csv', index=False)\n",
    "```\n",
    "\n",
    "#### `df.to_excel()`\n",
    "Writes DataFrame to an Excel file.\n",
    "```python\n",
    "df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n",
    "```\n",
    "\n",
    "#### `df.to_json()`\n",
    "Writes DataFrame to a JSON file.\n",
    "```python\n",
    "df.to_json('output.json')\n",
    "```\n",
    "\n",
    "### Basic DataFrame Information\n",
    "\n",
    "#### `df.head()`\n",
    "Returns the first n rows (default 5).\n",
    "```python\n",
    "df.head()      # First 5 rows\n",
    "df.head(10)    # First 10 rows\n",
    "```\n",
    "\n",
    "#### `df.tail()`\n",
    "Returns the last n rows (default 5).\n",
    "```python\n",
    "df.tail()      # Last 5 rows\n",
    "df.tail(10)    # Last 10 rows\n",
    "```\n",
    "\n",
    "#### `df.shape`\n",
    "Returns a tuple of (rows, columns).\n",
    "```python\n",
    "rows, cols = df.shape\n",
    "```\n",
    "\n",
    "#### `df.info()`\n",
    "Displays concise summary of DataFrame including data types and memory usage.\n",
    "```python\n",
    "df.info()\n",
    "```\n",
    "\n",
    "#### `df.describe()`\n",
    "Generates descriptive statistics for numerical columns.\n",
    "```python\n",
    "df.describe()                    # Numeric columns only\n",
    "df.describe(include='all')       # All columns\n",
    "```\n",
    "\n",
    "#### `df.columns`\n",
    "Returns column labels.\n",
    "```python\n",
    "columns = df.columns\n",
    "df.columns = ['new_col1', 'new_col2']  # Rename columns\n",
    "```\n",
    "\n",
    "#### `df.index`\n",
    "Returns the index (row labels).\n",
    "```python\n",
    "index = df.index\n",
    "df.index = range(1, len(df) + 1)  # Reset index\n",
    "```\n",
    "\n",
    "#### `df.dtypes`\n",
    "Returns the data type of each column.\n",
    "```python\n",
    "types = df.dtypes\n",
    "```\n",
    "\n",
    "### Selecting Data\n",
    "\n",
    "#### `df['column']` or `df.column`\n",
    "Selects a single column (returns Series).\n",
    "```python\n",
    "col = df['column_name']\n",
    "col = df.column_name\n",
    "```\n",
    "\n",
    "#### `df[['col1', 'col2']]`\n",
    "Selects multiple columns (returns DataFrame).\n",
    "```python\n",
    "subset = df[['col1', 'col2', 'col3']]\n",
    "```\n",
    "\n",
    "#### `df.loc[]`\n",
    "Label-based indexing for rows and columns.\n",
    "```python\n",
    "df.loc[0]                      # Single row by label\n",
    "df.loc[0:5]                    # Multiple rows\n",
    "df.loc[:, 'column']            # All rows, one column\n",
    "df.loc[0:5, ['col1', 'col2']]  # Rows and columns\n",
    "```\n",
    "\n",
    "#### `df.iloc[]`\n",
    "Integer position-based indexing.\n",
    "```python\n",
    "df.iloc[0]                     # First row\n",
    "df.iloc[0:5]                   # First 5 rows\n",
    "df.iloc[:, 0]                  # All rows, first column\n",
    "df.iloc[0:5, 0:3]              # Rows 0-4, columns 0-2\n",
    "```\n",
    "\n",
    "#### `df[df['column'] > value]`\n",
    "Boolean indexing to filter rows.\n",
    "```python\n",
    "df[df['age'] > 30]\n",
    "df[(df['age'] > 30) & (df['city'] == 'NYC')]\n",
    "```\n",
    "\n",
    "### Basic Operations\n",
    "\n",
    "#### `df.drop()`\n",
    "Removes rows or columns.\n",
    "```python\n",
    "df.drop('column_name', axis=1)           # Drop column\n",
    "df.drop(['col1', 'col2'], axis=1)        # Drop multiple columns\n",
    "df.drop([0, 1, 2], axis=0)               # Drop rows by index\n",
    "df.drop('column_name', axis=1, inplace=True)  # Modify in place\n",
    "```\n",
    "\n",
    "#### `df.rename()`\n",
    "Renames columns or index labels.\n",
    "```python\n",
    "df.rename(columns={'old_name': 'new_name'})\n",
    "df.rename(columns={'col1': 'new1', 'col2': 'new2'})\n",
    "df.rename(index={0: 'row1', 1: 'row2'})\n",
    "```\n",
    "\n",
    "#### `df.sort_values()`\n",
    "Sorts DataFrame by values.\n",
    "```python\n",
    "df.sort_values('column')                         # Ascending\n",
    "df.sort_values('column', ascending=False)        # Descending\n",
    "df.sort_values(['col1', 'col2'], ascending=[True, False])\n",
    "```\n",
    "\n",
    "#### `df.sort_index()`\n",
    "Sorts by index labels.\n",
    "```python\n",
    "df.sort_index()\n",
    "df.sort_index(ascending=False)\n",
    "```\n",
    "\n",
    "#### `df.reset_index()`\n",
    "Resets the index to default integer index.\n",
    "```python\n",
    "df.reset_index(drop=True)          # Drop old index\n",
    "df.reset_index()                   # Keep old index as column\n",
    "```\n",
    "\n",
    "#### `df.set_index()`\n",
    "Sets one or more columns as the index.\n",
    "```python\n",
    "df.set_index('column_name')\n",
    "df.set_index(['col1', 'col2'])\n",
    "```\n",
    "\n",
    "### Handling Missing Data\n",
    "\n",
    "#### `df.isna()` or `df.isnull()`\n",
    "Detects missing values (returns boolean DataFrame).\n",
    "```python\n",
    "df.isna()\n",
    "df['column'].isna()\n",
    "```\n",
    "\n",
    "#### `df.notna()` or `df.notnull()`\n",
    "Detects non-missing values.\n",
    "```python\n",
    "df.notna()\n",
    "df['column'].notna()\n",
    "```\n",
    "\n",
    "#### `df.dropna()`\n",
    "Removes rows or columns with missing values.\n",
    "```python\n",
    "df.dropna()                    # Drop rows with any NaN\n",
    "df.dropna(axis=1)              # Drop columns with any NaN\n",
    "df.dropna(how='all')           # Drop rows where all are NaN\n",
    "df.dropna(thresh=2)            # Keep rows with at least 2 non-NaN\n",
    "df.dropna(subset=['col1'])     # Drop based on specific columns\n",
    "```\n",
    "\n",
    "#### `df.fillna()`\n",
    "Fills missing values.\n",
    "```python\n",
    "df.fillna(0)                           # Fill with 0\n",
    "df.fillna(method='ffill')              # Forward fill\n",
    "df.fillna(method='bfill')              # Backward fill\n",
    "df.fillna(df.mean())                   # Fill with mean\n",
    "df['column'].fillna(value)             # Fill specific column\n",
    "```\n",
    "\n",
    "### Basic Statistics\n",
    "\n",
    "#### `df.mean()`\n",
    "Calculates mean of numeric columns.\n",
    "```python\n",
    "df.mean()                  # Mean of all numeric columns\n",
    "df['column'].mean()        # Mean of specific column\n",
    "df.mean(axis=1)            # Mean across rows\n",
    "```\n",
    "\n",
    "#### `df.median()`\n",
    "Calculates median.\n",
    "```python\n",
    "df.median()\n",
    "df['column'].median()\n",
    "```\n",
    "\n",
    "#### `df.sum()`\n",
    "Calculates sum.\n",
    "```python\n",
    "df.sum()\n",
    "df['column'].sum()\n",
    "df.sum(axis=1)             # Sum across rows\n",
    "```\n",
    "\n",
    "#### `df.min()` and `df.max()`\n",
    "Finds minimum and maximum values.\n",
    "```python\n",
    "df.min()\n",
    "df.max()\n",
    "df['column'].min()\n",
    "```\n",
    "\n",
    "#### `df.std()`\n",
    "Calculates standard deviation.\n",
    "```python\n",
    "df.std()\n",
    "df['column'].std()\n",
    "```\n",
    "\n",
    "#### `df.var()`\n",
    "Calculates variance.\n",
    "```python\n",
    "df.var()\n",
    "df['column'].var()\n",
    "```\n",
    "\n",
    "#### `df.count()`\n",
    "Counts non-null values.\n",
    "```python\n",
    "df.count()\n",
    "df['column'].count()\n",
    "```\n",
    "\n",
    "#### `df.value_counts()`\n",
    "Counts unique values in a Series.\n",
    "```python\n",
    "df['column'].value_counts()\n",
    "df['column'].value_counts(normalize=True)  # As proportions\n",
    "```\n",
    "\n",
    "#### `df.unique()`\n",
    "Returns unique values in a Series.\n",
    "```python\n",
    "df['column'].unique()\n",
    "```\n",
    "\n",
    "#### `df.nunique()`\n",
    "Counts unique values.\n",
    "```python\n",
    "df['column'].nunique()\n",
    "df.nunique()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44ad56",
   "metadata": {},
   "source": [
    "\n",
    "## Level 2: Intermediate Functions\n",
    "\n",
    "### Data Manipulation\n",
    "\n",
    "#### `df.apply()`\n",
    "Applies a function along an axis.\n",
    "```python\n",
    "df['column'].apply(lambda x: x * 2)\n",
    "df.apply(lambda x: x.max() - x.min())      # Apply to columns\n",
    "df.apply(lambda x: x.max() - x.min(), axis=1)  # Apply to rows\n",
    "```\n",
    "\n",
    "#### `df.applymap()`\n",
    "Applies a function element-wise (deprecated, use `df.map()` or `df.apply()`).\n",
    "```python\n",
    "df.applymap(lambda x: x * 2)\n",
    "# Or use df.map() in newer versions\n",
    "```\n",
    "\n",
    "#### `df.map()`\n",
    "Maps values of a Series using a dictionary or function.\n",
    "```python\n",
    "df['column'].map({'old': 'new', 'a': 'b'})\n",
    "df['column'].map(lambda x: x * 2)\n",
    "```\n",
    "\n",
    "#### `df.replace()`\n",
    "Replaces values in DataFrame.\n",
    "```python\n",
    "df.replace(0, np.nan)\n",
    "df.replace([0, 1], [10, 100])\n",
    "df.replace({'col1': {0: 10}, 'col2': {1: 100}})\n",
    "df['column'].replace('old', 'new')\n",
    "```\n",
    "\n",
    "#### `df.astype()`\n",
    "Converts data types.\n",
    "```python\n",
    "df['column'].astype(int)\n",
    "df['column'].astype('category')\n",
    "df.astype({'col1': int, 'col2': str})\n",
    "```\n",
    "\n",
    "#### `df.copy()`\n",
    "Creates a copy of the DataFrame.\n",
    "```python\n",
    "df_copy = df.copy()        # Deep copy\n",
    "df_copy = df.copy(deep=False)  # Shallow copy\n",
    "```\n",
    "\n",
    "### String Operations\n",
    "\n",
    "#### `df['column'].str.lower()`\n",
    "Converts strings to lowercase.\n",
    "```python\n",
    "df['column'].str.lower()\n",
    "```\n",
    "\n",
    "#### `df['column'].str.upper()`\n",
    "Converts strings to uppercase.\n",
    "```python\n",
    "df['column'].str.upper()\n",
    "```\n",
    "\n",
    "#### `df['column'].str.strip()`\n",
    "Removes leading/trailing whitespace.\n",
    "```python\n",
    "df['column'].str.strip()\n",
    "df['column'].str.lstrip()   # Left strip\n",
    "df['column'].str.rstrip()   # Right strip\n",
    "```\n",
    "\n",
    "#### `df['column'].str.contains()`\n",
    "Checks if string contains pattern.\n",
    "```python\n",
    "df['column'].str.contains('pattern')\n",
    "df['column'].str.contains('pattern', case=False)\n",
    "df['column'].str.contains('pat1|pat2', regex=True)\n",
    "```\n",
    "\n",
    "#### `df['column'].str.replace()`\n",
    "Replaces substring.\n",
    "```python\n",
    "df['column'].str.replace('old', 'new')\n",
    "df['column'].str.replace(r'\\d+', '', regex=True)\n",
    "```\n",
    "\n",
    "#### `df['column'].str.split()`\n",
    "Splits strings.\n",
    "```python\n",
    "df['column'].str.split(',')\n",
    "df['column'].str.split(',', expand=True)  # Creates separate columns\n",
    "```\n",
    "\n",
    "#### `df['column'].str.startswith()` / `endswith()`\n",
    "Checks string start/end.\n",
    "```python\n",
    "df['column'].str.startswith('prefix')\n",
    "df['column'].str.endswith('suffix')\n",
    "```\n",
    "\n",
    "#### `df['column'].str.len()`\n",
    "Gets string length.\n",
    "```python\n",
    "df['column'].str.len()\n",
    "```\n",
    "\n",
    "#### `df['column'].str.slice()`\n",
    "Slices strings.\n",
    "```python\n",
    "df['column'].str.slice(0, 5)  # First 5 characters\n",
    "df['column'].str[:5]          # Same as above\n",
    "```\n",
    "\n",
    "### Date/Time Operations\n",
    "\n",
    "#### `pd.to_datetime()`\n",
    "Converts to datetime.\n",
    "```python\n",
    "pd.to_datetime(df['date_column'])\n",
    "pd.to_datetime('2023-01-01')\n",
    "pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "```\n",
    "\n",
    "#### `df['date'].dt.year` / `month` / `day`\n",
    "Extracts date components.\n",
    "```python\n",
    "df['date'].dt.year\n",
    "df['date'].dt.month\n",
    "df['date'].dt.day\n",
    "df['date'].dt.hour\n",
    "df['date'].dt.minute\n",
    "df['date'].dt.dayofweek    # Monday=0, Sunday=6\n",
    "df['date'].dt.day_name()   # 'Monday', 'Tuesday', etc.\n",
    "```\n",
    "\n",
    "#### `df['date'].dt.strftime()`\n",
    "Formats datetime as string.\n",
    "```python\n",
    "df['date'].dt.strftime('%Y-%m-%d')\n",
    "df['date'].dt.strftime('%B %d, %Y')\n",
    "```\n",
    "\n",
    "#### `pd.date_range()`\n",
    "Creates a range of dates.\n",
    "```python\n",
    "pd.date_range('2023-01-01', '2023-12-31')\n",
    "pd.date_range('2023-01-01', periods=10)\n",
    "pd.date_range('2023-01-01', periods=12, freq='M')\n",
    "```\n",
    "\n",
    "### Grouping and Aggregation\n",
    "\n",
    "#### `df.groupby()`\n",
    "Groups DataFrame by one or more columns.\n",
    "```python\n",
    "df.groupby('column')\n",
    "df.groupby(['col1', 'col2'])\n",
    "df.groupby('column').mean()\n",
    "df.groupby('column')['value'].sum()\n",
    "```\n",
    "\n",
    "#### `df.agg()` / `df.aggregate()`\n",
    "Applies multiple aggregation functions.\n",
    "```python\n",
    "df.groupby('column').agg(['mean', 'sum', 'count'])\n",
    "df.groupby('column').agg({'col1': 'mean', 'col2': 'sum'})\n",
    "df.agg({'col1': ['mean', 'std'], 'col2': 'sum'})\n",
    "```\n",
    "\n",
    "#### `df.transform()`\n",
    "Transforms values while keeping same shape.\n",
    "```python\n",
    "df.groupby('column').transform('mean')\n",
    "df.groupby('column')['value'].transform(lambda x: x - x.mean())\n",
    "```\n",
    "\n",
    "#### `df.filter()`\n",
    "Filters groups based on condition.\n",
    "```python\n",
    "df.groupby('column').filter(lambda x: len(x) > 5)\n",
    "df.groupby('column').filter(lambda x: x['value'].sum() > 100)\n",
    "```\n",
    "\n",
    "### Combining DataFrames\n",
    "\n",
    "#### `pd.concat()`\n",
    "Concatenates DataFrames along an axis.\n",
    "```python\n",
    "pd.concat([df1, df2])                    # Vertical stack\n",
    "pd.concat([df1, df2], axis=1)            # Horizontal stack\n",
    "pd.concat([df1, df2], ignore_index=True)\n",
    "pd.concat([df1, df2], keys=['df1', 'df2'])\n",
    "```\n",
    "\n",
    "#### `df.merge()`\n",
    "Merges DataFrames (SQL-style joins).\n",
    "```python\n",
    "pd.merge(df1, df2, on='key')                  # Inner join\n",
    "pd.merge(df1, df2, on='key', how='left')      # Left join\n",
    "pd.merge(df1, df2, on='key', how='right')     # Right join\n",
    "pd.merge(df1, df2, on='key', how='outer')     # Outer join\n",
    "pd.merge(df1, df2, left_on='key1', right_on='key2')\n",
    "```\n",
    "\n",
    "#### `df.join()`\n",
    "Joins DataFrames on index.\n",
    "```python\n",
    "df1.join(df2)\n",
    "df1.join(df2, how='left')\n",
    "df1.join(df2, on='key')\n",
    "```\n",
    "\n",
    "#### `df.append()`\n",
    "Appends rows (deprecated, use `pd.concat()` instead).\n",
    "```python\n",
    "# Old way (deprecated)\n",
    "df.append(df2)\n",
    "# New way\n",
    "pd.concat([df, df2], ignore_index=True)\n",
    "```\n",
    "\n",
    "### Reshaping Data\n",
    "\n",
    "#### `df.pivot()`\n",
    "Reshapes data based on column values.\n",
    "```python\n",
    "df.pivot(index='date', columns='category', values='value')\n",
    "```\n",
    "\n",
    "#### `df.pivot_table()`\n",
    "Creates a pivot table with aggregation.\n",
    "```python\n",
    "df.pivot_table(values='value', index='row', columns='col')\n",
    "df.pivot_table(values='value', index='row', columns='col', aggfunc='mean')\n",
    "df.pivot_table(values='value', index='row', columns='col', fill_value=0)\n",
    "```\n",
    "\n",
    "#### `df.melt()`\n",
    "Unpivots DataFrame from wide to long format.\n",
    "```python\n",
    "df.melt(id_vars=['id'], value_vars=['col1', 'col2'])\n",
    "df.melt(id_vars='id', var_name='variable', value_name='value')\n",
    "```\n",
    "\n",
    "#### `df.stack()` and `df.unstack()`\n",
    "Pivots a level of column/row labels.\n",
    "```python\n",
    "df.stack()      # Columns to rows\n",
    "df.unstack()    # Rows to columns\n",
    "df.unstack(level=0)\n",
    "```\n",
    "\n",
    "#### `df.transpose()` or `df.T`\n",
    "Transposes DataFrame (swap rows and columns).\n",
    "```python\n",
    "df.T\n",
    "df.transpose()\n",
    "```\n",
    "\n",
    "### Duplicate Handling\n",
    "\n",
    "#### `df.duplicated()`\n",
    "Identifies duplicate rows.\n",
    "```python\n",
    "df.duplicated()\n",
    "df.duplicated(subset=['column'])\n",
    "df.duplicated(keep='first')    # Mark duplicates except first\n",
    "df.duplicated(keep='last')     # Mark duplicates except last\n",
    "df.duplicated(keep=False)      # Mark all duplicates\n",
    "```\n",
    "\n",
    "#### `df.drop_duplicates()`\n",
    "Removes duplicate rows.\n",
    "```python\n",
    "df.drop_duplicates()\n",
    "df.drop_duplicates(subset=['column'])\n",
    "df.drop_duplicates(keep='first')\n",
    "```\n",
    "\n",
    "### Binning and Discretization\n",
    "\n",
    "#### `pd.cut()`\n",
    "Bins values into discrete intervals.\n",
    "```python\n",
    "pd.cut(df['age'], bins=3)\n",
    "pd.cut(df['age'], bins=[0, 18, 65, 100], labels=['Child', 'Adult', 'Senior'])\n",
    "```\n",
    "\n",
    "#### `pd.qcut()`\n",
    "Bins based on quantiles.\n",
    "```python\n",
    "pd.qcut(df['value'], q=4)    # Quartiles\n",
    "pd.qcut(df['value'], q=10)   # Deciles\n",
    "```\n",
    "\n",
    "### Statistical Functions\n",
    "\n",
    "#### `df.corr()`\n",
    "Computes correlation matrix.\n",
    "```python\n",
    "df.corr()\n",
    "df.corr(method='pearson')\n",
    "df.corr(method='spearman')\n",
    "```\n",
    "\n",
    "#### `df.cov()`\n",
    "Computes covariance matrix.\n",
    "```python\n",
    "df.cov()\n",
    "```\n",
    "\n",
    "#### `df.rank()`\n",
    "Ranks values.\n",
    "```python\n",
    "df['column'].rank()\n",
    "df['column'].rank(ascending=False)\n",
    "df['column'].rank(method='dense')\n",
    "```\n",
    "\n",
    "#### `df.pct_change()`\n",
    "Computes percentage change.\n",
    "```python\n",
    "df['column'].pct_change()\n",
    "df.pct_change(periods=2)\n",
    "```\n",
    "\n",
    "#### `df.diff()`\n",
    "Computes first discrete difference.\n",
    "```python\n",
    "df['column'].diff()\n",
    "df.diff(periods=2)\n",
    "```\n",
    "\n",
    "#### `df.cumsum()` / `df.cumprod()`\n",
    "Computes cumulative sum/product.\n",
    "```python\n",
    "df['column'].cumsum()\n",
    "df['column'].cumprod()\n",
    "df.cumsum()\n",
    "```\n",
    "\n",
    "#### `df.cummax()` / `df.cummin()`\n",
    "Computes cumulative maximum/minimum.\n",
    "```python\n",
    "df['column'].cummax()\n",
    "df['column'].cummin()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b47d74",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Level 3: Advanced Functions\n",
    "\n",
    "### Advanced Grouping\n",
    "\n",
    "#### `df.groupby().size()`\n",
    "Returns size of each group.\n",
    "```python\n",
    "df.groupby('column').size()\n",
    "```\n",
    "\n",
    "#### `df.groupby().nth()`\n",
    "Takes nth value from each group.\n",
    "```python\n",
    "df.groupby('column').nth(0)    # First row of each group\n",
    "df.groupby('column').nth(-1)   # Last row of each group\n",
    "```\n",
    "\n",
    "#### `df.groupby().cumsum()` / `cumcount()`\n",
    "Cumulative operations within groups.\n",
    "```python\n",
    "df.groupby('column')['value'].cumsum()\n",
    "df.groupby('column').cumcount()\n",
    "```\n",
    "\n",
    "#### `df.groupby().rolling()`\n",
    "Rolling window calculations within groups.\n",
    "```python\n",
    "df.groupby('category')['value'].rolling(window=3).mean()\n",
    "```\n",
    "\n",
    "#### `df.groupby().expanding()`\n",
    "Expanding window calculations within groups.\n",
    "```python\n",
    "df.groupby('category')['value'].expanding().mean()\n",
    "```\n",
    "\n",
    "### Window Functions\n",
    "\n",
    "#### `df.rolling()`\n",
    "Creates rolling window calculations.\n",
    "```python\n",
    "df['column'].rolling(window=3).mean()\n",
    "df['column'].rolling(window=3, min_periods=1).sum()\n",
    "df.rolling(window=5).agg(['mean', 'std'])\n",
    "```\n",
    "\n",
    "#### `df.expanding()`\n",
    "Creates expanding window calculations.\n",
    "```python\n",
    "df['column'].expanding().mean()\n",
    "df['column'].expanding(min_periods=3).sum()\n",
    "```\n",
    "\n",
    "#### `df.ewm()`\n",
    "Exponentially weighted moving calculations.\n",
    "```python\n",
    "df['column'].ewm(span=10).mean()\n",
    "df['column'].ewm(alpha=0.5).mean()\n",
    "```\n",
    "\n",
    "### Multi-Index Operations\n",
    "\n",
    "#### `pd.MultiIndex.from_tuples()`\n",
    "Creates MultiIndex from tuples.\n",
    "```python\n",
    "index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1)])\n",
    "df = pd.DataFrame({'value': [1, 2, 3]}, index=index)\n",
    "```\n",
    "\n",
    "#### `pd.MultiIndex.from_product()`\n",
    "Creates MultiIndex from cartesian product.\n",
    "```python\n",
    "index = pd.MultiIndex.from_product([['A', 'B'], [1, 2, 3]])\n",
    "```\n",
    "\n",
    "#### `df.xs()`\n",
    "Cross-section from MultiIndex.\n",
    "```python\n",
    "df.xs('A', level=0)\n",
    "df.xs(('A', 1), level=[0, 1])\n",
    "```\n",
    "\n",
    "#### `df.swaplevel()`\n",
    "Swaps levels in MultiIndex.\n",
    "```python\n",
    "df.swaplevel(0, 1)\n",
    "```\n",
    "\n",
    "### Advanced Merging\n",
    "\n",
    "#### `pd.merge_asof()`\n",
    "Merge on nearest key.\n",
    "```python\n",
    "pd.merge_asof(df1, df2, on='date')\n",
    "pd.merge_asof(df1, df2, on='date', by='category')\n",
    "```\n",
    "\n",
    "#### `pd.merge_ordered()`\n",
    "Merge with optional fill method.\n",
    "```python\n",
    "pd.merge_ordered(df1, df2, on='date', fill_method='ffill')\n",
    "```\n",
    "\n",
    "### Categorical Data\n",
    "\n",
    "#### `df['column'].astype('category')`\n",
    "Converts to categorical data type.\n",
    "```python\n",
    "df['column'] = df['column'].astype('category')\n",
    "```\n",
    "\n",
    "#### `df['column'].cat.categories`\n",
    "Gets categories.\n",
    "```python\n",
    "categories = df['column'].cat.categories\n",
    "```\n",
    "\n",
    "#### `df['column'].cat.codes`\n",
    "Gets integer codes for categories.\n",
    "```python\n",
    "codes = df['column'].cat.codes\n",
    "```\n",
    "\n",
    "#### `df['column'].cat.rename_categories()`\n",
    "Renames categories.\n",
    "```python\n",
    "df['column'].cat.rename_categories({'old': 'new'})\n",
    "```\n",
    "\n",
    "#### `df['column'].cat.reorder_categories()`\n",
    "Reorders categories.\n",
    "```python\n",
    "df['column'].cat.reorder_categories(['low', 'medium', 'high'])\n",
    "```\n",
    "\n",
    "#### `df['column'].cat.add_categories()` / `remove_categories()`\n",
    "Adds or removes categories.\n",
    "```python\n",
    "df['column'].cat.add_categories(['new_cat'])\n",
    "df['column'].cat.remove_categories(['unwanted'])\n",
    "```\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "#### `df.memory_usage()`\n",
    "Shows memory usage of each column.\n",
    "```python\n",
    "df.memory_usage(deep=True)\n",
    "```\n",
    "\n",
    "#### `df.select_dtypes()`\n",
    "Selects columns by data type.\n",
    "```python\n",
    "df.select_dtypes(include=['int64', 'float64'])\n",
    "df.select_dtypes(exclude=['object'])\n",
    "```\n",
    "\n",
    "#### `pd.eval()`\n",
    "Evaluates expression efficiently.\n",
    "```python\n",
    "df.eval('C = A + B')\n",
    "result = pd.eval('df1 + df2')\n",
    "```\n",
    "\n",
    "#### `df.query()`\n",
    "Filters using expression string (more efficient).\n",
    "```python\n",
    "df.query('age > 30')\n",
    "df.query('age > 30 and city == \"NYC\"')\n",
    "df.query('age > @threshold')  # Use variable\n",
    "```\n",
    "\n",
    "### Advanced Indexing\n",
    "\n",
    "#### `df.where()`\n",
    "Replaces values where condition is False.\n",
    "```python\n",
    "df.where(df > 0, 0)  # Replace negative values with 0\n",
    "df.where(df['age'] > 30, other=0)\n",
    "```\n",
    "\n",
    "#### `df.mask()`\n",
    "Replaces values where condition is True.\n",
    "```python\n",
    "df.mask(df < 0, 0)  # Replace negative values with 0\n",
    "```\n",
    "\n",
    "#### `df.at[]` and `df.iat[]`\n",
    "Fast scalar value access.\n",
    "```python\n",
    "value = df.at[0, 'column']      # Label-based\n",
    "value = df.iat[0, 0]            # Position-based\n",
    "df.at[0, 'column'] = new_value  # Setting value\n",
    "```\n",
    "\n",
    "#### `df.get()`\n",
    "Gets item with default value if not found.\n",
    "```python\n",
    "df.get('column', default=None)\n",
    "```\n",
    "\n",
    "### Sampling and Random\n",
    "\n",
    "#### `df.sample()`\n",
    "Random sampling of rows.\n",
    "```python\n",
    "df.sample(n=10)                  # 10 random rows\n",
    "df.sample(frac=0.1)              # 10% of rows\n",
    "df.sample(n=5, replace=True)     # With replacement\n",
    "df.sample(n=10, random_state=42) # Reproducible\n",
    "```\n",
    "\n",
    "#### `df.nlargest()` / `df.nsmallest()`\n",
    "Returns n largest/smallest values.\n",
    "```python\n",
    "df.nlargest(10, 'column')\n",
    "df.nsmallest(5, 'column')\n",
    "df.nlargest(10, ['col1', 'col2'])\n",
    "```\n",
    "\n",
    "### Advanced String Operations\n",
    "\n",
    "#### `df['column'].str.extract()`\n",
    "Extracts groups from regex pattern.\n",
    "```python\n",
    "df['column'].str.extract(r'(\\d+)')\n",
    "df['column'].str.extract(r'(\\w+)-(\\d+)', expand=True)\n",
    "```\n",
    "\n",
    "#### `df['column'].str.findall()`\n",
    "Finds all occurrences of pattern.\n",
    "```python\n",
    "df['column'].str.findall(r'\\d+')\n",
    "```\n",
    "\n",
    "#### `df['column'].str.match()`\n",
    "Checks if string matches pattern.\n",
    "```python\n",
    "df['column'].str.match(r'^\\d+')\n",
    "```\n",
    "\n",
    "#### `df['column'].str.pad()`\n",
    "Pads strings to specified width.\n",
    "```python\n",
    "df['column'].str.pad(10, side='left', fillchar='0')\n",
    "```\n",
    "\n",
    "#### `df['column'].str.wrap()`\n",
    "Wraps long strings.\n",
    "```python\n",
    "df['column'].str.wrap(width=50)\n",
    "```\n",
    "\n",
    "### Time Series Specific\n",
    "\n",
    "#### `df.resample()`\n",
    "Resamples time-series data.\n",
    "```python\n",
    "df.resample('D').mean()     # Daily mean\n",
    "df.resample('W').sum()      # Weekly sum\n",
    "df.resample('M').last()     # Monthly last value\n",
    "df.resample('Q').agg(['mean', 'sum'])\n",
    "```\n",
    "\n",
    "#### `df.shift()`\n",
    "Shifts index by desired number of periods.\n",
    "```python\n",
    "df['column'].shift(1)       # Shift down 1 row\n",
    "df['column'].shift(-1)      # Shift up 1 row\n",
    "df.shift(periods=2, freq='D')  # Shift time index\n",
    "```\n",
    "\n",
    "#### `df.tshift()`\n",
    "Shift time index (deprecated, use `shift` with freq).\n",
    "```python\n",
    "df.shift(freq='D')\n",
    "```\n",
    "\n",
    "#### `df.asfreq()`\n",
    "Converts to specified frequency.\n",
    "```python\n",
    "df.asfreq('D')\n",
    "df.asfreq('H', method='ffill')\n",
    "```\n",
    "\n",
    "#### `df.between_time()`\n",
    "Selects values between times of day.\n",
    "```python\n",
    "df.between_time('09:00', '17:00')\n",
    "```\n",
    "\n",
    "#### `df.at_time()`\n",
    "Selects values at a particular time of day.\n",
    "```python\n",
    "df.at_time('10:30')\n",
    "```\n",
    "\n",
    "### Sparse Data\n",
    "\n",
    "#### `pd.SparseDtype()`\n",
    "Creates sparse data type.\n",
    "```python\n",
    "df['column'] = df['column'].astype(pd.SparseDtype('int', 0))\n",
    "```\n",
    "\n",
    "#### `df.sparse.to_dense()`\n",
    "Converts sparse to dense.\n",
    "```python\n",
    "df.sparse.to_dense()\n",
    "```\n",
    "\n",
    "### Style and Formatting\n",
    "\n",
    "#### `df.style.highlight_max()`\n",
    "Highlights maximum values.\n",
    "```python\n",
    "df.style.highlight_max(color='lightgreen')\n",
    "df.style.highlight_max(subset=['col1', 'col2'])\n",
    "```\n",
    "\n",
    "#### `df.style.highlight_min()`\n",
    "Highlights minimum values.\n",
    "```python\n",
    "df.style.highlight_min(color='lightcoral')\n",
    "```\n",
    "\n",
    "#### `df.style.background_gradient()`\n",
    "Applies color gradient.\n",
    "```python\n",
    "df.style.background_gradient(cmap='viridis')\n",
    "df.style.background_gradient(subset=['col1'], cmap='Blues')\n",
    "```\n",
    "\n",
    "#### `df.style.format()`\n",
    "Formats display values.\n",
    "```python\n",
    "df.style.format('{:.2f}')\n",
    "df.style.format({'col1': '{:.2%}', 'col2': '${:.2f}'})\n",
    "```\n",
    "\n",
    "#### `df.style.bar()`\n",
    "Displays bars in cells.\n",
    "```python\n",
    "df.style.bar(color='lightblue')\n",
    "df.style.bar(subset=['col1'], color='#d65f5f')\n",
    "```\n",
    "\n",
    "### Advanced IO\n",
    "\n",
    "#### `pd.read_sql()`\n",
    "Reads from SQL database.\n",
    "```python\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "df = pd.read_sql('SELECT * FROM table', conn)\n",
    "df = pd.read_sql_query('SELECT * FROM table WHERE id > 5', conn)\n",
    "```\n",
    "\n",
    "#### `df.to_sql()`\n",
    "Writes to SQL database.\n",
    "```python\n",
    "df.to_sql('table_name', conn, if_exists='replace')\n",
    "df.to_sql('table_name', conn, if_exists='append')\n",
    "```\n",
    "\n",
    "#### `pd.read_parquet()`\n",
    "Reads Parquet file.\n",
    "```python\n",
    "df = pd.read_parquet('file.parquet')\n",
    "```\n",
    "\n",
    "#### `df.to_parquet()`\n",
    "Writes to Parquet format.\n",
    "```python\n",
    "df.to_parquet('file.parquet', compression='gzip')\n",
    "```\n",
    "\n",
    "#### `pd.read_hdf()`\n",
    "Reads HDF5 file.\n",
    "```python\n",
    "df = pd.read_hdf('file.h5', 'key')\n",
    "```\n",
    "\n",
    "#### `df.to_hdf()`\n",
    "Writes to HDF5 format.\n",
    "```python\n",
    "df.to_hdf('file.h5', key='data', mode='w')\n",
    "```\n",
    "\n",
    "#### `pd.read_pickle()`\n",
    "Reads pickled pandas object.\n",
    "```python\n",
    "df = pd.read_pickle('file.pkl')\n",
    "```\n",
    "\n",
    "#### `df.to_pickle()`\n",
    "Writes to pickle format.\n",
    "```python\n",
    "df.to_pickle('file.pkl')\n",
    "```\n",
    "\n",
    "#### `pd.read_clipboard()`\n",
    "Reads from clipboard.\n",
    "```python\n",
    "df = pd.read_clipboard()\n",
    "```\n",
    "\n",
    "#### `df.to_clipboard()`\n",
    "Writes to clipboard.\n",
    "```python\n",
    "df.to_clipboard()\n",
    "```\n",
    "\n",
    "### Advanced Aggregation\n",
    "\n",
    "#### `df.pipe()`\n",
    "Applies chainable functions.\n",
    "```python\n",
    "def func1(df):\n",
    "    return df[df['value'] > 0]\n",
    "\n",
    "def func2(df):\n",
    "    return df.sort_values('value')\n",
    "\n",
    "result = df.pipe(func1).pipe(func2)\n",
    "```\n",
    "\n",
    "#### `df.assign()`\n",
    "Assigns new columns (chainable).\n",
    "```python\n",
    "df.assign(new_col=lambda x: x['col1'] * 2)\n",
    "df.assign(col1=lambda x: x['col1'] * 2, col2=lambda x: x['col1'] + x['col2'])\n",
    "```\n",
    "\n",
    "#### `pd.crosstab()`\n",
    "Computes cross-tabulation of two or more factors.\n",
    "```python\n",
    "pd.crosstab(df['col1'], df['col2'])\n",
    "pd.crosstab(df['col1'], df['col2'], normalize='all')\n",
    "pd.crosstab(df['col1'], df['col2'], values=df['col3'], aggfunc='mean')\n",
    "```\n",
    "\n",
    "#### `pd.cut()` with advanced options\n",
    "More sophisticated binning.\n",
    "```python\n",
    "pd.cut(df['age'], bins=5, labels=['A', 'B', 'C', 'D', 'E'])\n",
    "pd.cut(df['age'], bins=[0, 18, 30, 50, 100], right=False)\n",
    "pd.cut(df['age'], bins=5, retbins=True)  # Returns bins used\n",
    "```\n",
    "\n",
    "### Advanced Data Validation\n",
    "\n",
    "#### `df.isin()`\n",
    "Checks if values are in a list.\n",
    "```python\n",
    "df['column'].isin([1, 2, 3])\n",
    "df.isin({'col1': [1, 2], 'col2': ['a', 'b']})\n",
    "```\n",
    "\n",
    "#### `df.between()`\n",
    "Checks if values are between bounds.\n",
    "```python\n",
    "df['column'].between(10, 20)\n",
    "df['column'].between(10, 20, inclusive='neither')\n",
    "```\n",
    "\n",
    "#### `df.clip()`\n",
    "Trims values at input thresholds.\n",
    "```python\n",
    "df['column'].clip(lower=0, upper=100)\n",
    "df.clip(lower=0)\n",
    "```\n",
    "\n",
    "#### `df.interpolate()`\n",
    "Fills NaN values using interpolation.\n",
    "```python\n",
    "df['column'].interpolate()\n",
    "df['column'].interpolate(method='linear')\n",
    "df['column'].interpolate(method='polynomial', order=2)\n",
    "df['column'].interpolate(method='time')\n",
    "```\n",
    "\n",
    "### Advanced Boolean Operations\n",
    "\n",
    "#### `df.all()`\n",
    "Checks if all values are True.\n",
    "```python\n",
    "df.all()\n",
    "df['column'].all()\n",
    "(df > 0).all()\n",
    "```\n",
    "\n",
    "#### `df.any()`\n",
    "Checks if any value is True.\n",
    "```python\n",
    "df.any()\n",
    "df['column'].any()\n",
    "(df > 100).any()\n",
    "```\n",
    "\n",
    "#### `df.equals()`\n",
    "Checks if two DataFrames are equal.\n",
    "```python\n",
    "df1.equals(df2)\n",
    "```\n",
    "\n",
    "### Memory Optimization\n",
    "\n",
    "#### Downcast numeric types\n",
    "```python\n",
    "df['int_col'] = pd.to_numeric(df['int_col'], downcast='integer')\n",
    "df['float_col'] = pd.to_numeric(df['float_col'], downcast='float')\n",
    "```\n",
    "\n",
    "#### Convert to categorical for repeated strings\n",
    "```python\n",
    "df['category_col'] = df['category_col'].astype('category')\n",
    "```\n",
    "\n",
    "#### Use sparse for mostly zero/NaN data\n",
    "```python\n",
    "df['sparse_col'] = df['sparse_col'].astype(pd.SparseDtype('float', np.nan))\n",
    "```\n",
    "\n",
    "### Advanced Index Operations\n",
    "\n",
    "#### `df.reindex()`\n",
    "Conforms DataFrame to new index.\n",
    "```python\n",
    "df.reindex([0, 1, 2, 3, 4])\n",
    "df.reindex(columns=['col1', 'col2'])\n",
    "df.reindex(index=new_index, fill_value=0)\n",
    "df.reindex(index=new_index, method='ffill')\n",
    "```\n",
    "\n",
    "#### `df.reindex_like()`\n",
    "Reindexes to match another DataFrame.\n",
    "```python\n",
    "df1.reindex_like(df2)\n",
    "```\n",
    "\n",
    "#### `df.align()`\n",
    "Aligns two DataFrames on their axes.\n",
    "```python\n",
    "df1_aligned, df2_aligned = df1.align(df2, join='inner')\n",
    "df1_aligned, df2_aligned = df1.align(df2, join='outer', fill_value=0)\n",
    "```\n",
    "\n",
    "### Advanced Apply Operations\n",
    "\n",
    "#### `df.applymap()` replacement with `map()`\n",
    "Apply function element-wise (newer versions).\n",
    "```python\n",
    "df.map(lambda x: x * 2 if isinstance(x, (int, float)) else x)\n",
    "```\n",
    "\n",
    "#### Apply with result_type\n",
    "```python\n",
    "df.apply(lambda x: [x.min(), x.max()], result_type='expand')\n",
    "df.apply(lambda x: pd.Series([x.min(), x.max()]), axis=1)\n",
    "```\n",
    "\n",
    "### Advanced Combining\n",
    "\n",
    "#### `df.combine()`\n",
    "Combines two DataFrames with element-wise function.\n",
    "```python\n",
    "df1.combine(df2, lambda s1, s2: s1 if s1.sum() > s2.sum() else s2)\n",
    "```\n",
    "\n",
    "#### `df.combine_first()`\n",
    "Updates null elements with value from another DataFrame.\n",
    "```python\n",
    "df1.combine_first(df2)\n",
    "```\n",
    "\n",
    "#### `df.update()`\n",
    "Updates values in place.\n",
    "```python\n",
    "df1.update(df2)\n",
    "df.update(df2, overwrite=False)\n",
    "```\n",
    "\n",
    "### Advanced Iteration\n",
    "\n",
    "#### `df.items()`\n",
    "Iterates over (column name, Series) pairs.\n",
    "```python\n",
    "for col_name, col_data in df.items():\n",
    "    print(col_name, col_data.sum())\n",
    "```\n",
    "\n",
    "#### `df.iterrows()`\n",
    "Iterates over (index, Series) pairs for each row.\n",
    "```python\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx, row['column'])\n",
    "```\n",
    "\n",
    "#### `df.itertuples()`\n",
    "Iterates over rows as named tuples (faster than iterrows).\n",
    "```python\n",
    "for row in df.itertuples():\n",
    "    print(row.Index, row.column_name)\n",
    "```\n",
    "\n",
    "#### `df.items()` for columns\n",
    "```python\n",
    "for name, series in df.items():\n",
    "    print(f\"{name}: {series.mean()}\")\n",
    "```\n",
    "\n",
    "### JSON Operations\n",
    "\n",
    "#### `pd.json_normalize()`\n",
    "Normalizes semi-structured JSON data.\n",
    "```python\n",
    "df = pd.json_normalize(json_data)\n",
    "df = pd.json_normalize(json_data, record_path='items')\n",
    "df = pd.json_normalize(json_data, record_path='items', meta=['id', 'name'])\n",
    "```\n",
    "\n",
    "### Options and Settings\n",
    "\n",
    "#### `pd.set_option()` / `pd.get_option()`\n",
    "Sets/gets pandas options.\n",
    "```python\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.get_option('display.max_rows')\n",
    "```\n",
    "\n",
    "#### `pd.reset_option()`\n",
    "Resets option to default.\n",
    "```python\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('all')\n",
    "```\n",
    "\n",
    "#### Context manager for temporary options\n",
    "```python\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', 5):\n",
    "    print(df)\n",
    "```\n",
    "\n",
    "### Advanced Type Conversion\n",
    "\n",
    "#### `pd.to_numeric()`\n",
    "Converts to numeric type with error handling.\n",
    "```python\n",
    "pd.to_numeric(df['column'], errors='coerce')  # Invalid -> NaN\n",
    "pd.to_numeric(df['column'], errors='ignore')  # Keep invalid\n",
    "pd.to_numeric(df['column'], downcast='integer')\n",
    "```\n",
    "\n",
    "#### `pd.to_timedelta()`\n",
    "Converts to timedelta.\n",
    "```python\n",
    "pd.to_timedelta(df['duration'])\n",
    "pd.to_timedelta('1 days 2 hours')\n",
    "```\n",
    "\n",
    "#### `df.convert_dtypes()`\n",
    "Converts to best possible dtypes.\n",
    "```python\n",
    "df.convert_dtypes()\n",
    "```\n",
    "\n",
    "#### `df.infer_objects()`\n",
    "Attempts to infer better dtypes for object columns.\n",
    "```python\n",
    "df.infer_objects()\n",
    "```\n",
    "\n",
    "### Extension Arrays and Nullable Types\n",
    "\n",
    "#### Nullable integer types\n",
    "```python\n",
    "df['col'] = df['col'].astype('Int64')  # Capital I for nullable\n",
    "df['col'] = df['col'].astype(pd.Int64Dtype())\n",
    "```\n",
    "\n",
    "#### Nullable boolean\n",
    "```python\n",
    "df['col'] = df['col'].astype('boolean')\n",
    "df['col'] = df['col'].astype(pd.BooleanDtype())\n",
    "```\n",
    "\n",
    "#### String type (more efficient than object)\n",
    "```python\n",
    "df['col'] = df['col'].astype('string')\n",
    "df['col'] = df['col'].astype(pd.StringDtype())\n",
    "```\n",
    "\n",
    "### Accessor Methods\n",
    "\n",
    "#### `.str` accessor\n",
    "Already covered but includes advanced methods:\n",
    "```python\n",
    "df['text'].str.extractall(r'(\\d+)')\n",
    "df['text'].str.get_dummies(sep=',')\n",
    "df['text'].str.normalize('NFKD')\n",
    "```\n",
    "\n",
    "#### `.dt` accessor advanced\n",
    "```python\n",
    "df['date'].dt.tz_localize('UTC')\n",
    "df['date'].dt.tz_convert('US/Eastern')\n",
    "df['date'].dt.to_period('M')\n",
    "df['date'].dt.to_timestamp()\n",
    "df['date'].dt.quarter\n",
    "df['date'].dt.is_leap_year\n",
    "df['date'].dt.days_in_month\n",
    "```\n",
    "\n",
    "#### `.cat` accessor advanced\n",
    "```python\n",
    "df['cat_col'].cat.set_categories(['low', 'med', 'high'], ordered=True)\n",
    "df['cat_col'].cat.as_ordered()\n",
    "df['cat_col'].cat.as_unordered()\n",
    "```\n",
    "\n",
    "### Advanced Plotting (Basic Integration)\n",
    "\n",
    "#### `df.plot()`\n",
    "Basic plotting capabilities.\n",
    "```python\n",
    "df.plot()\n",
    "df.plot(kind='bar')\n",
    "df.plot(kind='barh')  # Horizontal bar\n",
    "df.plot(kind='hist')\n",
    "df.plot(kind='box')\n",
    "df.plot(kind='scatter', x='col1', y='col2')\n",
    "df.plot(kind='area')\n",
    "df.plot(kind='pie', y='column')\n",
    "df.plot(kind='density')\n",
    "df.plot(kind='hexbin', x='col1', y='col2', gridsize=20)\n",
    "```\n",
    "\n",
    "#### `df.hist()`\n",
    "Plots histogram.\n",
    "```python\n",
    "df.hist()\n",
    "df['column'].hist(bins=20)\n",
    "df.hist(column='col', by='category')\n",
    "```\n",
    "\n",
    "#### `df.boxplot()`\n",
    "Creates box plot.\n",
    "```python\n",
    "df.boxplot()\n",
    "df.boxplot(column='value', by='category')\n",
    "```\n",
    "\n",
    "### Working with Intervals\n",
    "\n",
    "#### `pd.Interval()`\n",
    "Creates an interval.\n",
    "```python\n",
    "interval = pd.Interval(left=0, right=5)\n",
    "```\n",
    "\n",
    "#### `pd.interval_range()`\n",
    "Creates IntervalIndex.\n",
    "```python\n",
    "intervals = pd.interval_range(start=0, end=5)\n",
    "intervals = pd.interval_range(start=0, periods=5, freq=1)\n",
    "```\n",
    "\n",
    "#### `pd.IntervalIndex.from_tuples()`\n",
    "Creates from tuples.\n",
    "```python\n",
    "pd.IntervalIndex.from_tuples([(0, 1), (1, 2), (2, 3)])\n",
    "```\n",
    "\n",
    "### Advanced Missing Data Handling\n",
    "\n",
    "#### `df.bfill()` / `df.ffill()`\n",
    "Backward/forward fill (alternative to fillna).\n",
    "```python\n",
    "df.ffill()    # Forward fill\n",
    "df.bfill()    # Backward fill\n",
    "df.ffill(limit=2)  # Limit consecutive fills\n",
    "```\n",
    "\n",
    "#### `df.interpolate()` advanced methods\n",
    "```python\n",
    "df.interpolate(method='polynomial', order=3)\n",
    "df.interpolate(method='spline', order=2)\n",
    "df.interpolate(method='akima')\n",
    "df.interpolate(method='krogh')\n",
    "```\n",
    "\n",
    "### Testing Functions\n",
    "\n",
    "#### `pd.testing.assert_frame_equal()`\n",
    "Asserts that two DataFrames are equal.\n",
    "```python\n",
    "pd.testing.assert_frame_equal(df1, df2)\n",
    "pd.testing.assert_frame_equal(df1, df2, check_dtype=False)\n",
    "```\n",
    "\n",
    "#### `pd.testing.assert_series_equal()`\n",
    "Asserts that two Series are equal.\n",
    "```python\n",
    "pd.testing.assert_series_equal(s1, s2)\n",
    "```\n",
    "\n",
    "### Utility Functions\n",
    "\n",
    "#### `pd.factorize()`\n",
    "Encodes object as enumerated type.\n",
    "```python\n",
    "codes, uniques = pd.factorize(df['column'])\n",
    "```\n",
    "\n",
    "#### `pd.get_dummies()`\n",
    "Converts categorical variables to dummy/indicator variables.\n",
    "```python\n",
    "pd.get_dummies(df['category'])\n",
    "pd.get_dummies(df, columns=['cat1', 'cat2'])\n",
    "pd.get_dummies(df['category'], prefix='cat')\n",
    "pd.get_dummies(df['category'], drop_first=True)\n",
    "```\n",
    "\n",
    "#### `pd.wide_to_long()`\n",
    "Reshapes wide to long format with more control than melt.\n",
    "```python\n",
    "pd.wide_to_long(df, stubnames='value', i='id', j='year')\n",
    "```\n",
    "\n",
    "#### `pd.from_dummies()`\n",
    "Converts dummy variables back to categorical (inverse of get_dummies).\n",
    "```python\n",
    "pd.from_dummies(dummies_df)\n",
    "```\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Use vectorized operations instead of loops**\n",
    "```python\n",
    "# Bad\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'new'] = df.loc[i, 'a'] + df.loc[i, 'b']\n",
    "\n",
    "# Good\n",
    "df['new'] = df['a'] + df['b']\n",
    "```\n",
    "\n",
    "2. **Use query() for complex filtering**\n",
    "```python\n",
    "# Faster\n",
    "df.query('age > 30 & city == \"NYC\"')\n",
    "\n",
    "# Slower\n",
    "df[(df['age'] > 30) & (df['city'] == 'NYC')]\n",
    "```\n",
    "\n",
    "3. **Use category dtype for repeated strings**\n",
    "```python\n",
    "df['category'] = df['category'].astype('category')\n",
    "```\n",
    "\n",
    "4. **Use itertuples() instead of iterrows()**\n",
    "```python\n",
    "# Faster\n",
    "for row in df.itertuples():\n",
    "    process(row.column)\n",
    "\n",
    "# Slower\n",
    "for idx, row in df.iterrows():\n",
    "    process(row['column'])\n",
    "```\n",
    "\n",
    "5. **Use eval() for complex expressions**\n",
    "```python\n",
    "df.eval('result = (a + b) * c')\n",
    "```\n",
    "\n",
    "### Common Patterns and Best Practices\n",
    "\n",
    "#### Method Chaining\n",
    "```python\n",
    "result = (df\n",
    "    .query('age > 30')\n",
    "    .groupby('city')\n",
    "    .agg({'salary': 'mean', 'count': 'size'})\n",
    "    .reset_index()\n",
    "    .sort_values('salary', ascending=False)\n",
    ")\n",
    "```\n",
    "\n",
    "#### Creating a DataFrame from scratch efficiently\n",
    "```python\n",
    "# Using a dictionary\n",
    "df = pd.DataFrame({\n",
    "    'A': range(1000),\n",
    "    'B': np.random.randn(1000),\n",
    "    'C': pd.date_range('2020-01-01', periods=1000)\n",
    "})\n",
    "```\n",
    "\n",
    "#### Conditional column creation\n",
    "```python\n",
    "df['category'] = df['value'].apply(\n",
    "    lambda x: 'high' if x > 100 else 'low' if x < 50 else 'medium'\n",
    ")\n",
    "\n",
    "# Or using np.select for better performance\n",
    "conditions = [df['value'] > 100, df['value'] < 50]\n",
    "choices = ['high', 'low']\n",
    "df['category'] = np.select(conditions, choices, default='medium')\n",
    "```\n",
    "\n",
    "#### Handling large files in chunks\n",
    "```python\n",
    "chunk_iter = pd.read_csv('large_file.csv', chunksize=10000)\n",
    "for chunk in chunk_iter:\n",
    "    process(chunk)\n",
    "```\n",
    "\n",
    "#### Creating bins and labels together\n",
    "```python\n",
    "df['age_group'] = pd.cut(\n",
    "    df['age'], \n",
    "    bins=[0, 18, 35, 60, 100],\n",
    "    labels=['Youth', 'Young Adult', 'Middle Age', 'Senior']\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdcd30",
   "metadata": {},
   "source": [
    "# Complete NumPy Guide: Vectors, 2D Arrays, and 3D Arrays\n",
    "\n",
    "## Understanding NumPy Array Dimensions\n",
    "\n",
    "### What are Vectors, 2D Arrays, and 3D Arrays?\n",
    "\n",
    "**1D Array (Vector)**\n",
    "- Single row or column of numbers\n",
    "- Shape: `(n,)` \n",
    "- Example: `[1, 2, 3, 4, 5]`\n",
    "- Used for: single list of values, time series data\n",
    "\n",
    "**2D Array (Matrix)**\n",
    "- Table with rows and columns\n",
    "- Shape: `(rows, columns)`\n",
    "- Example: `[[1, 2, 3], [4, 5, 6]]`  2 rows, 3 columns\n",
    "- Used for: spreadsheets, images (grayscale), data tables\n",
    "\n",
    "**3D Array (Tensor)**\n",
    "- Stack of 2D arrays\n",
    "- Shape: `(depth, rows, columns)`\n",
    "- Example: Stack of 3 matrices\n",
    "- Used for: RGB images, video frames, batch of data\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 1: Basic Vector Operations (1D Arrays)\n",
    "\n",
    "### Creating Vectors\n",
    "\n",
    "**np.array() - Create from list**\n",
    "```python\n",
    "vec = np.array([1, 2, 3, 4, 5])\n",
    "# Result: [1 2 3 4 5]\n",
    "# Shape: (5,)\n",
    "```\n",
    "\n",
    "**np.arange() - Range of values**\n",
    "```python\n",
    "vec = np.arange(0, 10, 2)\n",
    "# Result: [0 2 4 6 8]\n",
    "# Shape: (5,)\n",
    "```\n",
    "\n",
    "**np.linspace() - Evenly spaced values**\n",
    "```python\n",
    "vec = np.linspace(0, 1, 5)\n",
    "# Result: [0.   0.25 0.5  0.75 1.  ]\n",
    "# Shape: (5,)\n",
    "```\n",
    "\n",
    "**np.zeros() - Vector of zeros**\n",
    "```python\n",
    "vec = np.zeros(5)\n",
    "# Result: [0. 0. 0. 0. 0.]\n",
    "```\n",
    "\n",
    "**np.ones() - Vector of ones**\n",
    "```python\n",
    "vec = np.ones(5)\n",
    "# Result: [1. 1. 1. 1. 1.]\n",
    "```\n",
    "\n",
    "**np.random.rand() - Random vector**\n",
    "```python\n",
    "vec = np.random.rand(5)\n",
    "# Result: [0.23 0.67 0.45 0.89 0.12]  # random values\n",
    "```\n",
    "\n",
    "### Accessing Vector Elements\n",
    "\n",
    "**Indexing (starts from 0)**\n",
    "```python\n",
    "vec = np.array([10, 20, 30, 40, 50])\n",
    "vec[0]      # First element: 10\n",
    "vec[2]      # Third element: 30\n",
    "vec[-1]     # Last element: 50\n",
    "vec[-2]     # Second last: 40\n",
    "```\n",
    "\n",
    "**Slicing**\n",
    "```python\n",
    "vec[1:4]    # Elements from index 1 to 3: [20 30 40]\n",
    "vec[:3]     # First 3 elements: [10 20 30]\n",
    "vec[2:]     # From index 2 onwards: [30 40 50]\n",
    "vec[::2]    # Every 2nd element: [10 30 50]\n",
    "```\n",
    "\n",
    "### Vector Operations\n",
    "\n",
    "**Addition**\n",
    "```python\n",
    "vec1 = np.array([1, 2, 3])\n",
    "vec2 = np.array([4, 5, 6])\n",
    "result = vec1 + vec2\n",
    "# Result: [5 7 9]\n",
    "```\n",
    "\n",
    "**Multiplication (element-wise)**\n",
    "```python\n",
    "result = vec1 * vec2\n",
    "# Result: [4 10 18]\n",
    "```\n",
    "\n",
    "**Scalar Operations**\n",
    "```python\n",
    "vec = np.array([1, 2, 3, 4])\n",
    "vec + 10        # Add 10 to all: [11 12 13 14]\n",
    "vec * 5         # Multiply all by 5: [5 10 15 20]\n",
    "vec ** 2        # Square all: [1 4 9 16]\n",
    "```\n",
    "\n",
    "**Vector Statistics**\n",
    "```python\n",
    "vec = np.array([1, 2, 3, 4, 5])\n",
    "vec.sum()       # Sum: 15\n",
    "vec.mean()      # Average: 3.0\n",
    "vec.max()       # Maximum: 5\n",
    "vec.min()       # Minimum: 1\n",
    "vec.std()       # Standard deviation\n",
    "```\n",
    "\n",
    "**Dot Product (important for vectors!)**\n",
    "```python\n",
    "vec1 = np.array([1, 2, 3])\n",
    "vec2 = np.array([4, 5, 6])\n",
    "result = np.dot(vec1, vec2)\n",
    "# Result: 1*4 + 2*5 + 3*6 = 32\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 1: Basic 2D Array Operations (Matrices)\n",
    "\n",
    "### Creating 2D Arrays\n",
    "\n",
    "**np.array() - From nested list**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "# Shape: (2, 3)  2 rows, 3 columns\n",
    "```\n",
    "\n",
    "**np.zeros() - 2D array of zeros**\n",
    "```python\n",
    "matrix = np.zeros((3, 4))\n",
    "# Creates 3x4 matrix of zeros\n",
    "# Shape: (3, 4)\n",
    "```\n",
    "\n",
    "**np.ones() - 2D array of ones**\n",
    "```python\n",
    "matrix = np.ones((2, 5))\n",
    "# Creates 2x5 matrix of ones\n",
    "```\n",
    "\n",
    "**np.eye() - Identity matrix**\n",
    "```python\n",
    "matrix = np.eye(3)\n",
    "# Result:\n",
    "# [[1. 0. 0.]\n",
    "#  [0. 1. 0.]\n",
    "#  [0. 0. 1.]]\n",
    "```\n",
    "\n",
    "**np.random.rand() - Random 2D array**\n",
    "```python\n",
    "matrix = np.random.rand(3, 4)\n",
    "# Creates 3x4 matrix with random values\n",
    "```\n",
    "\n",
    "**np.arange().reshape() - Range reshaped**\n",
    "```python\n",
    "matrix = np.arange(12).reshape(3, 4)\n",
    "# Result:\n",
    "# [[ 0  1  2  3]\n",
    "#  [ 4  5  6  7]\n",
    "#  [ 8  9 10 11]]\n",
    "```\n",
    "\n",
    "### Understanding 2D Array Shape\n",
    "\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "\n",
    "matrix.shape        # (2, 3)  2 rows, 3 columns\n",
    "matrix.ndim         # 2  2 dimensions\n",
    "matrix.size         # 6  total elements\n",
    "```\n",
    "\n",
    "### Accessing 2D Array Elements\n",
    "\n",
    "**Single Element**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "matrix[0, 0]    # First row, first column: 1\n",
    "matrix[1, 2]    # Second row, third column: 6\n",
    "matrix[-1, -1]  # Last row, last column: 9\n",
    "```\n",
    "\n",
    "**Row Access**\n",
    "```python\n",
    "matrix[0]       # First row: [1 2 3]\n",
    "matrix[1]       # Second row: [4 5 6]\n",
    "matrix[-1]      # Last row: [7 8 9]\n",
    "```\n",
    "\n",
    "**Column Access**\n",
    "```python\n",
    "matrix[:, 0]    # First column: [1 4 7]\n",
    "matrix[:, 1]    # Second column: [2 5 8]\n",
    "matrix[:, -1]   # Last column: [3 6 9]\n",
    "```\n",
    "\n",
    "**Submatrix (Slicing)**\n",
    "```python\n",
    "matrix[0:2, 1:3]    # First 2 rows, columns 1-2\n",
    "# Result:\n",
    "# [[2 3]\n",
    "#  [5 6]]\n",
    "\n",
    "matrix[:2, :]       # First 2 rows, all columns\n",
    "matrix[:, 1:]       # All rows, from column 1 onwards\n",
    "```\n",
    "\n",
    "### 2D Array Operations\n",
    "\n",
    "**Row-wise Operations (axis=1)**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "\n",
    "matrix.sum(axis=1)      # Sum each row: [6 15]\n",
    "matrix.mean(axis=1)     # Mean of each row: [2. 5.]\n",
    "matrix.max(axis=1)      # Max in each row: [3 6]\n",
    "```\n",
    "\n",
    "**Column-wise Operations (axis=0)**\n",
    "```python\n",
    "matrix.sum(axis=0)      # Sum each column: [5 7 9]\n",
    "matrix.mean(axis=0)     # Mean of each column: [2.5 3.5 4.5]\n",
    "matrix.min(axis=0)      # Min in each column: [1 2 3]\n",
    "```\n",
    "\n",
    "**Matrix Addition**\n",
    "```python\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "C = A + B\n",
    "# Result:\n",
    "# [[ 6  8]\n",
    "#  [10 12]]\n",
    "```\n",
    "\n",
    "**Matrix Multiplication**\n",
    "```python\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "C = np.dot(A, B)  # or A @ B\n",
    "# Result:\n",
    "# [[19 22]\n",
    "#  [43 50]]\n",
    "```\n",
    "\n",
    "**Transpose**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "transposed = matrix.T\n",
    "# Result:\n",
    "# [[1 4]\n",
    "#  [2 5]\n",
    "#  [3 6]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 1: Basic 3D Array Operations\n",
    "\n",
    "### Creating 3D Arrays\n",
    "\n",
    "**np.zeros() - 3D array of zeros**\n",
    "```python\n",
    "arr_3d = np.zeros((2, 3, 4))\n",
    "# Shape: (2, 3, 4)\n",
    "# 2 layers, 3 rows, 4 columns\n",
    "```\n",
    "\n",
    "**np.ones() - 3D array of ones**\n",
    "```python\n",
    "arr_3d = np.ones((3, 2, 5))\n",
    "# 3 layers, 2 rows, 5 columns\n",
    "```\n",
    "\n",
    "**np.arange().reshape() - Range to 3D**\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "# Creates 2x3x4 array with values 0-23\n",
    "# Shape: (2, 3, 4)\n",
    "```\n",
    "\n",
    "**From nested lists**\n",
    "```python\n",
    "arr_3d = np.array([\n",
    "    [[1, 2], [3, 4]],          # First layer\n",
    "    [[5, 6], [7, 8]]           # Second layer\n",
    "])\n",
    "# Shape: (2, 2, 2)\n",
    "```\n",
    "\n",
    "### Understanding 3D Array Structure\n",
    "\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "# Shape: (2, 3, 4)\n",
    "# Think of it as: 2 matrices, each with 3 rows and 4 columns\n",
    "\n",
    "print(arr_3d.shape)     # (2, 3, 4)\n",
    "print(arr_3d.ndim)      # 3\n",
    "print(arr_3d.size)      # 24\n",
    "```\n",
    "\n",
    "### Accessing 3D Array Elements\n",
    "\n",
    "**Single Element**\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "arr_3d[0, 0, 0]     # First layer, first row, first column\n",
    "arr_3d[1, 2, 3]     # Second layer, third row, fourth column\n",
    "```\n",
    "\n",
    "**Getting Layers**\n",
    "```python\n",
    "arr_3d[0]           # First complete layer (3x4 matrix)\n",
    "arr_3d[1]           # Second complete layer (3x4 matrix)\n",
    "```\n",
    "\n",
    "**Getting Rows from specific layer**\n",
    "```python\n",
    "arr_3d[0, 0]        # First row of first layer\n",
    "arr_3d[1, 2]        # Third row of second layer\n",
    "```\n",
    "\n",
    "**Getting Columns**\n",
    "```python\n",
    "arr_3d[:, :, 0]     # First column from all layers\n",
    "arr_3d[0, :, 1]     # Second column from first layer\n",
    "```\n",
    "\n",
    "### 3D Array Operations\n",
    "\n",
    "**Operations along different axes**\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "\n",
    "# axis=0  across layers\n",
    "arr_3d.sum(axis=0)      # Sum across layers  (3, 4) result\n",
    "\n",
    "# axis=1  across rows (within each layer)\n",
    "arr_3d.sum(axis=1)      # Sum across rows  (2, 4) result\n",
    "\n",
    "# axis=2  across columns (within each row)\n",
    "arr_3d.sum(axis=2)      # Sum across columns  (2, 3) result\n",
    "```\n",
    "\n",
    "**Flattening 3D to 1D**\n",
    "```python\n",
    "arr_3d = np.arange(8).reshape(2, 2, 2)\n",
    "flat = arr_3d.flatten()\n",
    "# Result: [0 1 2 3 4 5 6 7]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 2: Intermediate Vector/Matrix Operations\n",
    "\n",
    "### Vector Advanced Operations\n",
    "\n",
    "**Vector Magnitude (Length)**\n",
    "```python\n",
    "vec = np.array([3, 4])\n",
    "magnitude = np.linalg.norm(vec)\n",
    "# Result: 5.0 (because sqrt(3 + 4) = 5)\n",
    "```\n",
    "\n",
    "**Unit Vector (Normalized)**\n",
    "```python\n",
    "vec = np.array([3, 4])\n",
    "unit_vec = vec / np.linalg.norm(vec)\n",
    "# Result: [0.6 0.8]\n",
    "```\n",
    "\n",
    "**Cross Product (3D vectors only)**\n",
    "```python\n",
    "vec1 = np.array([1, 0, 0])\n",
    "vec2 = np.array([0, 1, 0])\n",
    "cross = np.cross(vec1, vec2)\n",
    "# Result: [0 0 1]\n",
    "```\n",
    "\n",
    "**Outer Product**\n",
    "```python\n",
    "vec1 = np.array([1, 2, 3])\n",
    "vec2 = np.array([4, 5])\n",
    "outer = np.outer(vec1, vec2)\n",
    "# Result:\n",
    "# [[ 4  5]\n",
    "#  [ 8 10]\n",
    "#  [12 15]]\n",
    "```\n",
    "\n",
    "### 2D Array Reshaping\n",
    "\n",
    "**Reshape**\n",
    "```python\n",
    "arr = np.arange(12)\n",
    "matrix = arr.reshape(3, 4)      # 3x4 matrix\n",
    "matrix = arr.reshape(4, 3)      # 4x3 matrix\n",
    "matrix = arr.reshape(2, 6)      # 2x6 matrix\n",
    "matrix = arr.reshape(2, -1)     # 2 rows, auto-calculate columns\n",
    "```\n",
    "\n",
    "**Flatten vs Ravel**\n",
    "```python\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "flat1 = matrix.flatten()    # Creates copy\n",
    "flat2 = matrix.ravel()      # Creates view (when possible)\n",
    "```\n",
    "\n",
    "### Stacking and Splitting\n",
    "\n",
    "**Vertical Stack (vstack) - Stack rows**\n",
    "```python\n",
    "arr1 = np.array([[1, 2, 3]])\n",
    "arr2 = np.array([[4, 5, 6]])\n",
    "result = np.vstack((arr1, arr2))\n",
    "# Result:\n",
    "# [[1 2 3]\n",
    "#  [4 5 6]]\n",
    "```\n",
    "\n",
    "**Horizontal Stack (hstack) - Stack columns**\n",
    "```python\n",
    "arr1 = np.array([[1], [2]])\n",
    "arr2 = np.array([[3], [4]])\n",
    "result = np.hstack((arr1, arr2))\n",
    "# Result:\n",
    "# [[1 3]\n",
    "#  [2 4]]\n",
    "```\n",
    "\n",
    "**Concatenate**\n",
    "```python\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6]])\n",
    "\n",
    "# Along rows (axis=0)\n",
    "result = np.concatenate((arr1, arr2), axis=0)\n",
    "# Result:\n",
    "# [[1 2]\n",
    "#  [3 4]\n",
    "#  [5 6]]\n",
    "\n",
    "# Along columns (axis=1) - shapes must match!\n",
    "```\n",
    "\n",
    "**Split**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8]])\n",
    "\n",
    "# Split into 2 parts along columns\n",
    "left, right = np.hsplit(matrix, 2)\n",
    "# left: [[1 2], [5 6]]\n",
    "# right: [[3 4], [7 8]]\n",
    "```\n",
    "\n",
    "### Matrix Operations\n",
    "\n",
    "**Determinant**\n",
    "```python\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "det = np.linalg.det(matrix)\n",
    "# Result: -2.0\n",
    "```\n",
    "\n",
    "**Inverse**\n",
    "```python\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "inv = np.linalg.inv(matrix)\n",
    "# Result:\n",
    "# [[-2.   1. ]\n",
    "#  [ 1.5 -0.5]]\n",
    "```\n",
    "\n",
    "**Eigenvalues and Eigenvectors**\n",
    "```python\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "```\n",
    "\n",
    "**Matrix Power**\n",
    "```python\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "squared = np.linalg.matrix_power(matrix, 2)\n",
    "# Same as: matrix @ matrix\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 2: Intermediate 3D Operations\n",
    "\n",
    "### Stacking 2D Arrays into 3D\n",
    "\n",
    "**Stack along new axis**\n",
    "```python\n",
    "matrix1 = np.array([[1, 2], [3, 4]])\n",
    "matrix2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Stack to create depth\n",
    "arr_3d = np.stack((matrix1, matrix2), axis=0)\n",
    "# Shape: (2, 2, 2)\n",
    "```\n",
    "\n",
    "**dstack - Depth stack**\n",
    "```python\n",
    "arr_3d = np.dstack((matrix1, matrix2))\n",
    "# Stacks along third dimension\n",
    "```\n",
    "\n",
    "### Transposing 3D Arrays\n",
    "\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "# Original shape: (2, 3, 4)\n",
    "\n",
    "transposed = np.transpose(arr_3d, (1, 0, 2))\n",
    "# New shape: (3, 2, 4)\n",
    "# Axes reordered: axis 1  axis 0, axis 0  axis 1, axis 2  axis 2\n",
    "```\n",
    "\n",
    "### Swapping Axes\n",
    "\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "swapped = np.swapaxes(arr_3d, 0, 1)\n",
    "# Swaps first and second axes\n",
    "# New shape: (3, 2, 4)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## LEVEL 3: Advanced Operations\n",
    "\n",
    "### Broadcasting\n",
    "\n",
    "**What is Broadcasting?**\n",
    "Broadcasting allows operations on arrays of different shapes.\n",
    "\n",
    "**1D + 2D Broadcasting**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "vec = np.array([10, 20, 30])\n",
    "\n",
    "result = matrix + vec\n",
    "# vec is broadcast to each row\n",
    "# Result:\n",
    "# [[11 22 33]\n",
    "#  [14 25 36]]\n",
    "```\n",
    "\n",
    "**Column Broadcasting**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "vec = np.array([[10], [20]])\n",
    "\n",
    "result = matrix + vec\n",
    "# Result:\n",
    "# [[11 12 13]\n",
    "#  [24 25 26]]\n",
    "```\n",
    "\n",
    "### Advanced Indexing\n",
    "\n",
    "**Boolean Masking (2D)**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Get all values > 5\n",
    "result = matrix[matrix > 5]\n",
    "# Result: [6 7 8 9]\n",
    "\n",
    "# Set all values > 5 to 0\n",
    "matrix[matrix > 5] = 0\n",
    "```\n",
    "\n",
    "**Fancy Indexing (2D)**\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Get specific rows\n",
    "rows = matrix[[0, 2]]\n",
    "# Result: [[1 2 3], [7 8 9]]\n",
    "\n",
    "# Get specific elements\n",
    "elements = matrix[[0, 1, 2], [0, 1, 2]]\n",
    "# Gets: (0,0), (1,1), (2,2)  diagonal\n",
    "# Result: [1 5 9]\n",
    "```\n",
    "\n",
    "### Advanced 3D Operations\n",
    "\n",
    "**Meshgrid - Creating coordinate arrays**\n",
    "```python\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# X: [[1 2 3]\n",
    "#      [1 2 3]]\n",
    "# Y: [[4 4 4]\n",
    "#      [5 5 5]]\n",
    "```\n",
    "\n",
    "**Einstein Summation (einsum)**\n",
    "```python\n",
    "# Matrix multiplication\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "C = np.einsum('ij,jk->ik', A, B)\n",
    "# Same as: A @ B\n",
    "\n",
    "# Trace (sum of diagonal)\n",
    "trace = np.einsum('ii', A)\n",
    "\n",
    "# Batch matrix multiplication (3D)\n",
    "A_batch = np.random.rand(10, 3, 4)  # 10 matrices of 3x4\n",
    "B_batch = np.random.rand(10, 4, 5)  # 10 matrices of 4x5\n",
    "C_batch = np.einsum('bij,bjk->bik', A_batch, B_batch)\n",
    "# Result: 10 matrices of 3x5\n",
    "```\n",
    "\n",
    "### Tensor Operations (3D+)\n",
    "\n",
    "**Batched Operations**\n",
    "```python\n",
    "# Process multiple images at once\n",
    "images = np.random.rand(32, 224, 224, 3)\n",
    "# 32 images, 224x224 pixels, 3 color channels\n",
    "\n",
    "# Mean across color channels\n",
    "gray_images = images.mean(axis=3)\n",
    "# Result: (32, 224, 224)\n",
    "```\n",
    "\n",
    "**4D Arrays (Common in Deep Learning)**\n",
    "```python\n",
    "# Batch of RGB images\n",
    "batch = np.random.rand(32, 64, 64, 3)\n",
    "# Shape: (batch_size, height, width, channels)\n",
    "\n",
    "print(batch.shape)      # (32, 64, 64, 3)\n",
    "print(batch[0].shape)   # (64, 64, 3) - First image\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Reference: Axis Understanding\n",
    "\n",
    "### For 2D Arrays (Matrix)\n",
    "```python\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "\n",
    "# axis=0  Down the rows (column-wise operation)\n",
    "matrix.sum(axis=0)  # [5 7 9] - sum each column\n",
    "\n",
    "# axis=1  Across the columns (row-wise operation)\n",
    "matrix.sum(axis=1)  # [6 15] - sum each row\n",
    "```\n",
    "\n",
    "### For 3D Arrays\n",
    "```python\n",
    "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
    "# Shape: (2, 3, 4)\n",
    "\n",
    "# axis=0  across depth (layers)\n",
    "# axis=1  across rows\n",
    "# axis=2  across columns\n",
    "```\n",
    "\n",
    "### Memory Rule\n",
    "- **axis=0**  First dimension (outermost)\n",
    "- **axis=1**  Second dimension (middle)\n",
    "- **axis=2**  Third dimension (innermost)\n",
    "- **axis=-1**  Last dimension\n",
    "\n",
    "---\n",
    "\n",
    "## Common Use Cases\n",
    "\n",
    "### Image as 2D Array (Grayscale)\n",
    "```python\n",
    "image = np.random.randint(0, 256, (100, 100))\n",
    "# 100x100 grayscale image\n",
    "# Each value is pixel intensity (0-255)\n",
    "```\n",
    "\n",
    "### Image as 3D Array (RGB)\n",
    "```python\n",
    "image = np.random.randint(0, 256, (100, 100, 3))\n",
    "# 100x100 RGB image\n",
    "# Shape: (height, width, channels)\n",
    "# channels: 0=Red, 1=Green, 2=Blue\n",
    "```\n",
    "\n",
    "### Video as 4D Array\n",
    "```python\n",
    "video = np.random.randint(0, 256, (30, 1920, 1080, 3))\n",
    "# Shape: (frames, height, width, channels)\n",
    "# 30 frames, 1920x1080 resolution, RGB\n",
    "```\n",
    "\n",
    "### Dataset as 2D Array\n",
    "```python\n",
    "data = np.array([[25, 170, 1],    # age, height, gender\n",
    "                 [30, 165, 0],\n",
    "                 [28, 180, 1]])\n",
    "# Shape: (samples, features)\n",
    "# Each row is one data sample\n",
    "```\n",
    "\n",
    "This guide covers everything about vectors, 2D arrays, and 3D arrays in a clear, organized way!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238267a1",
   "metadata": {},
   "source": [
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf36bac",
   "metadata": {},
   "source": [
    "# SciPy Library - Ordered Notes\n",
    "\n",
    "## 1. Visualization (scipy.misc - limited, use matplotlib/seaborn instead)\n",
    "\n",
    "**Note:** SciPy has minimal visualization. Use `matplotlib` or `seaborn` for plotting.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: Plot a signal\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Filtering (scipy.signal)\n",
    "\n",
    "### `signal.butter(N, Wn, btype='low')`\n",
    "Design Butterworth filter (N=order, Wn=cutoff frequency)\n",
    "```python\n",
    "from scipy import signal\n",
    "b, a = signal.butter(4, 0.2, 'low')\n",
    "```\n",
    "\n",
    "### `signal.filtfilt(b, a, data)`\n",
    "Zero-phase digital filtering (forward-backward)\n",
    "```python\n",
    "filtered = signal.filtfilt(b, a, data)\n",
    "```\n",
    "\n",
    "### `signal.lfilter(b, a, data)`\n",
    "One-directional digital filter\n",
    "```python\n",
    "filtered = signal.lfilter(b, a, data)\n",
    "```\n",
    "\n",
    "### `signal.medfilt(data, kernel_size)`\n",
    "Median filter for noise reduction\n",
    "```python\n",
    "filtered = signal.medfilt(data, kernel_size=5)\n",
    "```\n",
    "\n",
    "### `signal.savgol_filter(data, window_length, polyorder)`\n",
    "Savitzky-Golay smoothing filter\n",
    "```python\n",
    "smoothed = signal.savgol_filter(data, 51, 3)\n",
    "```\n",
    "\n",
    "### `signal.wiener(data)`\n",
    "Wiener filter for denoising\n",
    "```python\n",
    "denoised = signal.wiener(data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Spectral Analysis (scipy.signal, scipy.fft)\n",
    "\n",
    "### `fft.fft(signal)`\n",
    "Fast Fourier Transform\n",
    "```python\n",
    "from scipy.fft import fft, fftfreq\n",
    "spectrum = fft(signal)\n",
    "```\n",
    "\n",
    "### `fft.ifft(spectrum)`\n",
    "Inverse FFT\n",
    "```python\n",
    "reconstructed = fft.ifft(spectrum)\n",
    "```\n",
    "\n",
    "### `fft.fftfreq(n, d)`\n",
    "Frequency bins for FFT (n=samples, d=sample spacing)\n",
    "```python\n",
    "freqs = fft.fftfreq(len(signal), 1/fs)\n",
    "```\n",
    "\n",
    "### `signal.periodogram(data, fs)`\n",
    "Power spectral density estimation\n",
    "```python\n",
    "f, Pxx = signal.periodogram(data, fs=1000)\n",
    "```\n",
    "\n",
    "### `signal.welch(data, fs)`\n",
    "Welch's method for PSD (reduces noise)\n",
    "```python\n",
    "f, Pxx = signal.welch(data, fs=1000, nperseg=256)\n",
    "```\n",
    "\n",
    "### `signal.spectrogram(data, fs)`\n",
    "Time-frequency spectrogram\n",
    "```python\n",
    "f, t, Sxx = signal.spectrogram(data, fs=1000)\n",
    "plt.pcolormesh(t, f, 10*np.log10(Sxx))\n",
    "```\n",
    "\n",
    "### `signal.stft(data, fs)`\n",
    "Short-Time Fourier Transform\n",
    "```python\n",
    "f, t, Zxx = signal.stft(data, fs=1000)\n",
    "```\n",
    "\n",
    "### `signal.istft(Zxx, fs)`\n",
    "Inverse STFT\n",
    "```python\n",
    "t, reconstructed = signal.istft(Zxx, fs=1000)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Optimization (scipy.optimize)\n",
    "\n",
    "### `optimize.minimize(fun, x0, method)`\n",
    "Minimize scalar/vector function\n",
    "```python\n",
    "from scipy import optimize\n",
    "result = optimize.minimize(lambda x: x**2, x0=2)\n",
    "```\n",
    "\n",
    "### `optimize.minimize_scalar(fun)`\n",
    "Minimize single-variable function\n",
    "```python\n",
    "result = optimize.minimize_scalar(lambda x: (x-2)**2)\n",
    "```\n",
    "\n",
    "### `optimize.curve_fit(f, xdata, ydata)`\n",
    "Fit function to data (nonlinear least squares)\n",
    "```python\n",
    "params, cov = optimize.curve_fit(lambda x, a, b: a*x+b, xdata, ydata)\n",
    "```\n",
    "\n",
    "### `optimize.root(fun, x0)`\n",
    "Find roots of equations\n",
    "```python\n",
    "sol = optimize.root(lambda x: x**2 - 4, x0=1)\n",
    "```\n",
    "\n",
    "### `optimize.fsolve(func, x0)`\n",
    "Solve nonlinear equations\n",
    "```python\n",
    "solution = optimize.fsolve(lambda x: x**2 - 4, x0=1)\n",
    "```\n",
    "\n",
    "### `optimize.least_squares(fun, x0)`\n",
    "Solve nonlinear least-squares problems\n",
    "```python\n",
    "result = optimize.least_squares(lambda x: x**2 - 4, x0=1)\n",
    "```\n",
    "\n",
    "### `optimize.linprog(c, A_ub, b_ub)`\n",
    "Linear programming minimization\n",
    "```python\n",
    "result = optimize.linprog([1, 2], A_ub=[[-1, 1]], b_ub=[1])\n",
    "```\n",
    "\n",
    "### `optimize.differential_evolution(func, bounds)`\n",
    "Global optimization using genetic algorithm\n",
    "```python\n",
    "result = optimize.differential_evolution(lambda x: x**2, bounds=[(-5, 5)])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Example Pipeline\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate noisy signal\n",
    "fs = 1000\n",
    "t = np.linspace(0, 1, fs)\n",
    "clean = np.sin(2*np.pi*50*t)\n",
    "noisy = clean + 0.5*np.random.randn(fs)\n",
    "\n",
    "# 1. Filter\n",
    "b, a = signal.butter(4, 0.15, 'low')\n",
    "filtered = signal.filtfilt(b, a, noisy)\n",
    "\n",
    "# 2. Spectral Analysis\n",
    "freqs = fftfreq(len(filtered), 1/fs)\n",
    "spectrum = np.abs(fft(filtered))\n",
    "\n",
    "# 3. Visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131); plt.plot(t, noisy); plt.title('Noisy')\n",
    "plt.subplot(132); plt.plot(t, filtered); plt.title('Filtered')\n",
    "plt.subplot(133); plt.plot(freqs[:fs//2], spectrum[:fs//2]); plt.title('Spectrum')\n",
    "plt.tight_layout(); plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** Run each cell in Jupyter for interactive exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57fe79",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbe1b0",
   "metadata": {},
   "source": [
    "# Matplotlib Complete Guide - Level 1 to 3\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 1: FUNDAMENTALS (Beginner)\n",
    "\n",
    "### 1.1 Basic Plotting Structure\n",
    "\n",
    "**Two Ways to Plot:**\n",
    "1. **Pyplot Interface** (MATLAB-style, quick and easy)\n",
    "2. **Object-Oriented Interface** (Professional, more control)\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Method 1: Pyplot (Simple)\n",
    "plt.plot([1, 2, 3], [4, 5, 6])\n",
    "plt.show()\n",
    "\n",
    "# Method 2: Object-Oriented (Recommended)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([1, 2, 3], [4, 5, 6])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 1.2 Basic Plot Types\n",
    "\n",
    "#### Line Plot\n",
    "```python\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_title('Sine Wave')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Scatter Plot\n",
    "```python\n",
    "x = np.random.rand(50)\n",
    "y = np.random.rand(50)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c='red', marker='o', s=100, alpha=0.5)\n",
    "ax.set_title('Scatter Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Bar Plot\n",
    "```python\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "values = [23, 45, 56, 78]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(categories, values, color='skyblue')\n",
    "ax.set_ylabel('Values')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Histogram\n",
    "```python\n",
    "data = np.random.randn(1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=30, color='green', alpha=0.7)\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 1.3 Essential Customizations\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot with customizations\n",
    "ax.plot(x, y, \n",
    "        color='blue',        # Color\n",
    "        linewidth=2,         # Line width\n",
    "        linestyle='--',      # Line style: '-', '--', '-.', ':'\n",
    "        marker='o',          # Marker style\n",
    "        markersize=5,        # Marker size\n",
    "        label='Sine')        # Legend label\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('X-axis', fontsize=12)\n",
    "ax.set_ylabel('Y-axis', fontsize=12)\n",
    "ax.set_title('My Plot', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Grid and legend\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 1.4 Saving Figures\n",
    "\n",
    "```python\n",
    "# Save in different formats\n",
    "fig.savefig('plot.png', dpi=300, bbox_inches='tight')\n",
    "fig.savefig('plot.pdf', bbox_inches='tight')\n",
    "fig.savefig('plot.svg', bbox_inches='tight')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 2: INTERMEDIATE\n",
    "\n",
    "### 2.1 Subplots and Layout\n",
    "\n",
    "#### Creating Multiple Subplots\n",
    "```python\n",
    "# Method 1: Regular grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "axes[0, 0].plot(x, np.sin(x))\n",
    "axes[0, 0].set_title('Sine')\n",
    "\n",
    "axes[0, 1].plot(x, np.cos(x))\n",
    "axes[0, 1].set_title('Cosine')\n",
    "\n",
    "axes[1, 0].plot(x, np.tan(x))\n",
    "axes[1, 0].set_title('Tangent')\n",
    "\n",
    "axes[1, 1].plot(x, x**2)\n",
    "axes[1, 1].set_title('Quadratic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Custom Subplot Layout\n",
    "```python\n",
    "# Using subplot2grid for custom layouts\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)  # Top spanning\n",
    "ax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)  # Middle left\n",
    "ax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)  # Right side\n",
    "ax4 = plt.subplot2grid((3, 3), (2, 0))\n",
    "ax5 = plt.subplot2grid((3, 3), (2, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2.2 Advanced Plot Types\n",
    "\n",
    "#### Contour Plot\n",
    "```python\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sin(np.sqrt(X**2 + Y**2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "contour = ax.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "plt.colorbar(contour, ax=ax)\n",
    "ax.set_title('Contour Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Heatmap\n",
    "```python\n",
    "data = np.random.rand(10, 10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(data, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.set_title('Heatmap')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Box Plot\n",
    "```python\n",
    "data = [np.random.normal(0, std, 100) for std in range(1, 4)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data, labels=['A', 'B', 'C'])\n",
    "ax.set_ylabel('Values')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Violin Plot\n",
    "```python\n",
    "fig, ax = plt.subplots()\n",
    "parts = ax.violinplot(data, showmeans=True, showmedians=True)\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(['A', 'B', 'C'])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2.3 Customizing Axes\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "# Axis limits\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "\n",
    "# Axis scales\n",
    "ax.set_xscale('log')  # 'linear', 'log', 'symlog', 'logit'\n",
    "ax.set_yscale('linear')\n",
    "\n",
    "# Tick customization\n",
    "ax.set_xticks([0, 2, 4, 6, 8, 10])\n",
    "ax.set_xticklabels(['zero', 'two', 'four', 'six', 'eight', 'ten'], rotation=45)\n",
    "\n",
    "# Spine customization\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2.4 Text and Annotations\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x))\n",
    "\n",
    "# Add text\n",
    "ax.text(5, 0.5, 'Peak region', fontsize=12, color='red')\n",
    "\n",
    "# Annotate with arrow\n",
    "ax.annotate('Maximum', \n",
    "            xy=(np.pi/2, 1),           # Point to annotate\n",
    "            xytext=(3, 0.5),            # Text position\n",
    "            arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2.5 Colors and Colormaps\n",
    "\n",
    "```python\n",
    "# Using colormaps\n",
    "x = np.linspace(0, 10, 100)\n",
    "colors = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(10):\n",
    "    ax.plot(x, np.sin(x + i*0.5), color=plt.cm.viridis(i/10))\n",
    "\n",
    "# Common colormaps: 'viridis', 'plasma', 'inferno', 'magma', 'cividis'\n",
    "# Sequential: 'Blues', 'Greens', 'Reds', 'YlOrRd'\n",
    "# Diverging: 'RdBu', 'coolwarm', 'seismic'\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 3: ADVANCED\n",
    "\n",
    "### 3.1 Figure and Axes Architecture\n",
    "\n",
    "```python\n",
    "# Complete control over figure creation\n",
    "fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "\n",
    "# Add axes manually with positions [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.5, 0.8, 0.4])   # Main plot\n",
    "ax2 = fig.add_axes([0.1, 0.1, 0.8, 0.3])   # Secondary plot\n",
    "ax3 = fig.add_axes([0.7, 0.65, 0.2, 0.2])  # Inset plot\n",
    "\n",
    "ax1.plot(x, np.sin(x))\n",
    "ax2.plot(x, np.cos(x))\n",
    "ax3.scatter(x[:10], np.sin(x[:10]))\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.2 Twin Axes (Multiple Y-axes)\n",
    "\n",
    "```python\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# First y-axis\n",
    "ax1.plot(x, np.sin(x), 'b-', label='Sine')\n",
    "ax1.set_xlabel('X-axis')\n",
    "ax1.set_ylabel('Sine', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Second y-axis sharing same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, np.exp(x/5), 'r-', label='Exponential')\n",
    "ax2.set_ylabel('Exponential', color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.3 3D Plotting\n",
    "\n",
    "```python\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 3D Surface\n",
    "x = np.linspace(-5, 5, 50)\n",
    "y = np.linspace(-5, 5, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sin(np.sqrt(X**2 + Y**2))\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
    "fig.colorbar(surf, ax=ax)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('3D Surface')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 3D Scatter and Lines\n",
    "```python\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 3D Scatter\n",
    "x = np.random.rand(100)\n",
    "y = np.random.rand(100)\n",
    "z = np.random.rand(100)\n",
    "colors = z\n",
    "\n",
    "ax.scatter(x, y, z, c=colors, cmap='viridis', s=50)\n",
    "\n",
    "# 3D Line\n",
    "t = np.linspace(0, 10, 100)\n",
    "ax.plot(np.sin(t), np.cos(t), t, 'r-', linewidth=2)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.4 Animation\n",
    "\n",
    "```python\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "\n",
    "def animate(frame):\n",
    "    line.set_ydata(np.sin(x + frame/10))\n",
    "    return line,\n",
    "\n",
    "ani = FuncAnimation(fig, animate, frames=100, interval=50, blit=True)\n",
    "plt.show()\n",
    "\n",
    "# Save animation\n",
    "# ani.save('animation.gif', writer='pillow', fps=20)\n",
    "```\n",
    "\n",
    "### 3.5 Style Sheets\n",
    "\n",
    "```python\n",
    "# View available styles\n",
    "print(plt.style.available)\n",
    "\n",
    "# Use a style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "# Other popular: 'ggplot', 'fivethirtyeight', 'bmh', 'dark_background'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x))\n",
    "plt.show()\n",
    "\n",
    "# Reset to default\n",
    "plt.style.use('default')\n",
    "```\n",
    "\n",
    "### 3.6 Custom Styling with rcParams\n",
    "\n",
    "```python\n",
    "# Temporarily modify settings\n",
    "with plt.rc_context({'font.size': 14, 'lines.linewidth': 2}):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "# Permanently modify (for session)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "```\n",
    "\n",
    "### 3.7 Complex Layouts with GridSpec\n",
    "\n",
    "```python\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Create subplots with different sizes\n",
    "ax1 = fig.add_subplot(gs[0, :])      # Top row, all columns\n",
    "ax2 = fig.add_subplot(gs[1, :-1])    # Middle row, first 2 columns\n",
    "ax3 = fig.add_subplot(gs[1:, -1])    # Last column, bottom 2 rows\n",
    "ax4 = fig.add_subplot(gs[-1, 0])     # Bottom left\n",
    "ax5 = fig.add_subplot(gs[-1, 1])     # Bottom middle\n",
    "\n",
    "ax1.plot(x, np.sin(x))\n",
    "ax2.plot(x, np.cos(x))\n",
    "ax3.plot(x, np.tan(x))\n",
    "ax4.scatter(x[:20], np.sin(x[:20]))\n",
    "ax5.bar(range(10), np.random.rand(10))\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.8 Interactive Features\n",
    "\n",
    "```python\n",
    "# Enable interactive mode\n",
    "plt.ion()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot([], [])\n",
    "ax.set_xlim(0, 2*np.pi)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "for i in range(100):\n",
    "    x = np.linspace(0, 2*np.pi, 100)\n",
    "    y = np.sin(x + i/10)\n",
    "    line.set_data(x, y)\n",
    "    plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.9 Event Handling\n",
    "\n",
    "```python\n",
    "def onclick(event):\n",
    "    if event.inaxes:\n",
    "        print(f'Clicked at x={event.xdata:.2f}, y={event.ydata:.2f}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x))\n",
    "\n",
    "# Connect event\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.10 Professional Publication-Ready Plots\n",
    "\n",
    "```python\n",
    "# Set publication style\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 1.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# Plot with error bars\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = 2*x + 1 + np.random.randn(20)\n",
    "yerr = np.random.rand(20)\n",
    "\n",
    "ax.errorbar(x, y, yerr=yerr, fmt='o', capsize=3, capthick=1.5, \n",
    "            label='Data', color='#2C3E50', markersize=6)\n",
    "\n",
    "# Fit line\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(x, p(x), '--', color='#E74C3C', linewidth=2, label='Fit')\n",
    "\n",
    "ax.set_xlabel('X-axis (units)', fontsize=12)\n",
    "ax.set_ylabel('Y-axis (units)', fontsize=12)\n",
    "ax.set_title('Publication-Ready Plot', fontsize=14, fontweight='bold')\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('publication_plot.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  KEY CONCEPTS TO REMEMBER\n",
    "\n",
    "### Figure vs Axes\n",
    "- **Figure**: The entire window/page (container)\n",
    "- **Axes**: The actual plot area (can have multiple per figure)\n",
    "\n",
    "### Common Patterns\n",
    "```python\n",
    "# Always use this pattern for control\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# For multiple plots\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "```\n",
    "\n",
    "### Essential Methods\n",
    "- **ax.plot()** - line plots\n",
    "- **ax.scatter()** - scatter plots\n",
    "- **ax.bar()** - bar charts\n",
    "- **ax.hist()** - histograms\n",
    "- **ax.imshow()** - images/heatmaps\n",
    "- **ax.contour()** - contour plots\n",
    "\n",
    "### Customization Hierarchy\n",
    "1. Figure level (size, dpi)\n",
    "2. Axes level (limits, labels, title)\n",
    "3. Plot level (color, style, markers)\n",
    "4. Global level (rcParams, styles)\n",
    "\n",
    "---\n",
    "\n",
    "##  QUICK REFERENCE\n",
    "\n",
    "### Line Styles\n",
    "- `'-'` solid\n",
    "- `'--'` dashed\n",
    "- `'-.'` dash-dot\n",
    "- `':'` dotted\n",
    "\n",
    "### Markers\n",
    "- `'o'` circle\n",
    "- `'s'` square\n",
    "- `'^'` triangle up\n",
    "- `'*'` star\n",
    "- `'+'` plus\n",
    "- `'x'` x-mark\n",
    "\n",
    "### Colors\n",
    "- Named: `'red'`, `'blue'`, `'green'`\n",
    "- Hex: `'#FF5733'`\n",
    "- RGB tuple: `(0.1, 0.2, 0.5)`\n",
    "- Short codes: `'r'`, `'b'`, `'g'`, `'c'`, `'m'`, `'y'`, `'k'`, `'w'`\n",
    "\n",
    "### Common Arguments\n",
    "- **figsize**: `(width, height)` in inches\n",
    "- **dpi**: dots per inch (resolution)\n",
    "- **alpha**: transparency (0-1)\n",
    "- **linewidth** or **lw**: line thickness\n",
    "- **markersize** or **ms**: marker size\n",
    "- **label**: for legends\n",
    "\n",
    "---\n",
    "\n",
    "##  PRACTICE EXERCISES\n",
    "\n",
    "1. **Level 1**: Create a line plot with custom colors, labels, and grid\n",
    "2. **Level 2**: Create a 2x2 subplot with different plot types in each\n",
    "3. **Level 3**: Create an animated 3D surface plot with custom colormap\n",
    "\n",
    "**Remember**: Practice with real data! Use `plt.show()` to display, always use `fig, ax = plt.subplots()` pattern, and save your work with `fig.savefig()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a75bc",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296d0af",
   "metadata": {},
   "source": [
    "# Scikit-Learn Complete Guide - Level 1 to 3\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 1: FUNDAMENTALS (Beginner)\n",
    "\n",
    "### 1.1 Basic Workflow\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load data\n",
    "X, y = load_data()  # Features and target\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Preprocess\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 6. Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "```\n",
    "\n",
    "### 1.2 Loading Sample Datasets\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris, load_diabetes, load_wine, make_classification\n",
    "\n",
    "# Built-in datasets\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "```\n",
    "\n",
    "### 1.3 Train-Test Split\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Basic split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Stratified split (keeps class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "```\n",
    "\n",
    "### 1.4 Basic Preprocessing\n",
    "\n",
    "#### StandardScaler (Z-score normalization)\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same parameters\n",
    "```\n",
    "\n",
    "#### MinMaxScaler (0-1 scaling)\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "#### Label Encoding\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(['cat', 'dog', 'cat', 'bird'])\n",
    "# Output: [0, 2, 0, 1]\n",
    "```\n",
    "\n",
    "### 1.5 Basic Models\n",
    "\n",
    "#### Linear Regression\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'Intercept: {model.intercept_}')\n",
    "```\n",
    "\n",
    "#### Logistic Regression (Classification)\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)  # Probabilities\n",
    "```\n",
    "\n",
    "#### Decision Tree\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "#### K-Nearest Neighbors\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "### 1.6 Basic Evaluation Metrics\n",
    "\n",
    "#### Classification Metrics\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'F1-Score: {f1:.3f}')\n",
    "```\n",
    "\n",
    "#### Regression Metrics\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse:.3f}')\n",
    "print(f'MAE: {mae:.3f}')\n",
    "print(f'R: {r2:.3f}')\n",
    "```\n",
    "\n",
    "#### Confusion Matrix\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 2: INTERMEDIATE\n",
    "\n",
    "### 2.1 Cross-Validation\n",
    "\n",
    "#### K-Fold Cross-Validation\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5)  # 5-fold CV\n",
    "\n",
    "print(f'Scores: {scores}')\n",
    "print(f'Mean: {scores.mean():.3f} (+/- {scores.std():.3f})')\n",
    "```\n",
    "\n",
    "#### Stratified K-Fold\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=skf)\n",
    "```\n",
    "\n",
    "#### Cross-Val Predict\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "```\n",
    "\n",
    "### 2.2 Hyperparameter Tuning\n",
    "\n",
    "#### GridSearchCV (Exhaustive search)\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_:.3f}')\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "```\n",
    "\n",
    "#### RandomizedSearchCV (Faster)\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': randint(2, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_dist, n_iter=20, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search.best_params_}')\n",
    "```\n",
    "\n",
    "### 2.3 Advanced Preprocessing\n",
    "\n",
    "#### One-Hot Encoding\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X_categorical)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "```\n",
    "\n",
    "#### Polynomial Features\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### Handling Missing Values\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Other strategies: 'median', 'most_frequent', 'constant'\n",
    "```\n",
    "\n",
    "#### Feature Selection\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)  # Select top 10 features\n",
    "X_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_features = selector.get_support(indices=True)\n",
    "```\n",
    "\n",
    "### 2.4 Ensemble Methods\n",
    "\n",
    "#### Random Forest\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "```\n",
    "\n",
    "#### Gradient Boosting\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### AdaBoost\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "base_model = DecisionTreeClassifier(max_depth=1)\n",
    "model = AdaBoostClassifier(estimator=base_model, n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### Voting Classifier\n",
    "```python\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC(probability=True)\n",
    "model3 = RandomForestClassifier()\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('lr', model1), ('svc', model2), ('rf', model3)],\n",
    "    voting='soft'  # 'soft' uses probabilities, 'hard' uses majority vote\n",
    ")\n",
    "voting.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 2.5 Support Vector Machines\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# Classification\n",
    "svc = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Regression\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Kernels: 'linear', 'poly', 'rbf', 'sigmoid'\n",
    "```\n",
    "\n",
    "### 2.6 Clustering (Unsupervised)\n",
    "\n",
    "#### K-Means\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Inertia (within-cluster sum of squares)\n",
    "inertia = kmeans.inertia_\n",
    "```\n",
    "\n",
    "#### DBSCAN\n",
    "```python\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(X)\n",
    "```\n",
    "\n",
    "#### Hierarchical Clustering\n",
    "```python\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "labels = model.fit_predict(X)\n",
    "```\n",
    "\n",
    "### 2.7 Dimensionality Reduction\n",
    "\n",
    "#### PCA (Principal Component Analysis)\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Explained variance\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f'Explained variance: {explained_var}')\n",
    "```\n",
    "\n",
    "#### t-SNE\n",
    "```python\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  LEVEL 3: ADVANCED\n",
    "\n",
    "### 3.1 Pipelines\n",
    "\n",
    "#### Basic Pipeline\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "```\n",
    "\n",
    "#### Pipeline with Feature Selection\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(f_classif, k=10)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### ColumnTransformer (Different preprocessing for different columns)\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features = [0, 1, 2]\n",
    "categorical_features = [3, 4]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 3.2 Custom Transformers\n",
    "\n",
    "```python\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if self.columns:\n",
    "            X_copy[:, self.columns] = np.log1p(X_copy[:, self.columns])\n",
    "        else:\n",
    "            X_copy = np.log1p(X_copy)\n",
    "        return X_copy\n",
    "\n",
    "# Use in pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('log_transform', LogTransformer(columns=[0, 1])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "```\n",
    "\n",
    "### 3.3 Model Persistence\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Save model (joblib - recommended)\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Using pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "```\n",
    "\n",
    "### 3.4 Advanced Cross-Validation\n",
    "\n",
    "#### Time Series Split\n",
    "```python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    # Train and evaluate\n",
    "```\n",
    "\n",
    "#### Leave-One-Out CV\n",
    "```python\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, X, y, cv=loo)\n",
    "```\n",
    "\n",
    "### 3.5 Calibration\n",
    "\n",
    "```python\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "base_model = RandomForestClassifier()\n",
    "calibrated_model = CalibratedClassifierCV(base_model, cv=5, method='sigmoid')\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "# Get calibrated probabilities\n",
    "proba = calibrated_model.predict_proba(X_test)\n",
    "```\n",
    "\n",
    "### 3.6 Multi-Output Models\n",
    "\n",
    "```python\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "# Multiple target variables\n",
    "model = MultiOutputClassifier(RandomForestClassifier())\n",
    "model.fit(X_train, y_train_multi)  # y_train_multi has multiple columns\n",
    "```\n",
    "\n",
    "### 3.7 Imbalanced Data Handling\n",
    "\n",
    "#### Class Weights\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### SMOTE (Synthetic Minority Over-sampling)\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 3.8 Learning Curves\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    model, X, y, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "plt.plot(train_sizes, val_scores.mean(axis=1), label='Validation score')\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.9 Partial Dependence Plots\n",
    "\n",
    "```python\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "PartialDependenceDisplay.from_estimator(model, X_train, features=[0, 1, (0, 1)], ax=ax)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3.10 Advanced Metrics\n",
    "\n",
    "#### ROC Curve and AUC\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Precision-Recall Curve\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "plt.plot(recall, precision, label=f'AP = {ap:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Classification Report\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "```\n",
    "\n",
    "### 3.11 Neural Networks (MLPClassifier/Regressor)\n",
    "\n",
    "```python\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 3.12 Bayesian Optimization\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective(params):\n",
    "    n_estimators, max_depth = int(params[0]), int(params[1])\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3).mean()\n",
    "    return -score  # Minimize negative score\n",
    "\n",
    "result = minimize(objective, x0=[100, 10], bounds=[(50, 200), (5, 20)], method='L-BFGS-B')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  KEY CONCEPTS TO REMEMBER\n",
    "\n",
    "### Sklearn API Pattern\n",
    "All estimators follow the same pattern:\n",
    "```python\n",
    "model = Model(parameters)      # Initialize\n",
    "model.fit(X_train, y_train)    # Train\n",
    "predictions = model.predict(X_test)  # Predict\n",
    "```\n",
    "\n",
    "### Transformers vs Estimators\n",
    "- **Transformers**: Transform data (`.fit_transform()`, `.transform()`)\n",
    "- **Estimators**: Make predictions (`.fit()`, `.predict()`)\n",
    "- **Both**: Can be chained in pipelines\n",
    "\n",
    "### Cross-Validation Best Practices\n",
    "- Always use CV for model evaluation\n",
    "- Use `stratified` splits for classification\n",
    "- Use `TimeSeriesSplit` for time-series data\n",
    "- Never use test data during CV\n",
    "\n",
    "### Pipeline Benefits\n",
    "- Prevents data leakage\n",
    "- Simplifies code\n",
    "- Easy to deploy\n",
    "- Enables grid search on entire pipeline\n",
    "\n",
    "---\n",
    "\n",
    "##  QUICK REFERENCE\n",
    "\n",
    "### Model Selection Guide\n",
    "\n",
    "**Classification:**\n",
    "- Small dataset: Logistic Regression, SVM\n",
    "- Large dataset: Random Forest, Gradient Boosting\n",
    "- High dimensional: Naive Bayes, Linear SVM\n",
    "- Non-linear: Random Forest, SVM (RBF kernel)\n",
    "\n",
    "**Regression:**\n",
    "- Linear relationships: Linear Regression, Ridge, Lasso\n",
    "- Non-linear: Random Forest, Gradient Boosting, SVR\n",
    "- Many features: Ridge, Lasso (regularization)\n",
    "\n",
    "**Clustering:**\n",
    "- Known number of clusters: K-Means\n",
    "- Unknown clusters: DBSCAN, Hierarchical\n",
    "- High dimensional: Spectral Clustering\n",
    "\n",
    "### Common Hyperparameters\n",
    "\n",
    "**Random Forest:**\n",
    "- `n_estimators`: 100-500\n",
    "- `max_depth`: 5-20\n",
    "- `min_samples_split`: 2-10\n",
    "\n",
    "**Gradient Boosting:**\n",
    "- `n_estimators`: 100-1000\n",
    "- `learning_rate`: 0.01-0.1\n",
    "- `max_depth`: 3-7\n",
    "\n",
    "**SVM:**\n",
    "- `C`: 0.1-100 (regularization)\n",
    "- `gamma`: 'scale' or 0.001-1\n",
    "- `kernel`: 'rbf', 'linear', 'poly'\n",
    "\n",
    "### Metrics Cheat Sheet\n",
    "\n",
    "**Classification:**\n",
    "- Balanced classes: Accuracy\n",
    "- Imbalanced: F1-score, ROC-AUC\n",
    "- Cost-sensitive: Precision/Recall\n",
    "\n",
    "**Regression:**\n",
    "- Standard: MSE, RMSE\n",
    "- Outliers present: MAE\n",
    "- Comparison: R\n",
    "\n",
    "---\n",
    "\n",
    "##  BEST PRACTICES\n",
    "\n",
    "1. **Always split data before any preprocessing**\n",
    "2. **Use pipelines to prevent data leakage**\n",
    "3. **Scale features for distance-based algorithms (KNN, SVM)**\n",
    "4. **Use cross-validation for model selection**\n",
    "5. **Grid search on validation set, final evaluation on test set**\n",
    "6. **Check for overfitting (compare train vs validation scores)**\n",
    "7. **Save models with versioning**\n",
    "8. **Document hyperparameters and preprocessing steps**\n",
    "\n",
    "---\n",
    "\n",
    "##  PRACTICE WORKFLOW\n",
    "\n",
    "```python\n",
    "# 1. Load and explore data\n",
    "X, y = load_data()\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# 4. Hyperparameter tuning with CV\n",
    "param_grid = {'model__n_estimators': [100, 200], 'model__max_depth': [5, 10]}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "\n",
    "# 6. Save model\n",
    "joblib.dump(best_model, 'final_model.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32dfed",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
